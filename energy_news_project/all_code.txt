===== C:\Users\SK-GROUP\PycharmProjects\PythonProject\energy_news_project\bot\handlers\callback_handlers.py =====
# bot/handlers/callback_handlers.py
import logging
from typing import Optional
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import ContextTypes
from telegram.error import TelegramError

from bot.database import SafeNewsDB
from bot.services.telegram_service import TelegramService
from bot.formatters import format_news_for_publication

logger = logging.getLogger(__name__)


class CallbackHandlers:
    """Handlers for inline keyboard callbacks."""

    def __init__(self, database: SafeNewsDB, telegram_service: TelegramService):
        self.db = database
        self.telegram = telegram_service

    async def button_handler(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle callback button presses from moderation messages."""
        query = update.callback_query
        if not query:
            return

        await query.answer()

        try:
            # Parse callback data
            if "|" not in query.data:
                await query.edit_message_text("⚠️ Неверный формат данных кнопки.")
                return

            action, news_id = query.data.split("|", 1)
            logger.info(f"Processing action: {action} for news: {news_id}")

            # Get news data
            data_entry = self.db.get_news(news_id)
            if not data_entry:
                await query.edit_message_text("⚠️ Новость не найдена в базе данных.")
                return

            # Route to appropriate handler
            if action == "approve":
                await self._handle_approve(query, news_id, data_entry, context)
            elif action == "reject":
                await self._handle_reject(query, news_id, data_entry, context)
            elif action == "edit":
                await self._handle_edit(query, news_id, data_entry, context)
            else:
                await query.edit_message_text(f"⚠️ Неизвестное действие: {action}")

        except Exception as e:
            logger.error(f"Callback handler error: {e}", exc_info=True)
            try:
                await query.edit_message_text(f"⚠️ Ошибка обработки: {str(e)}")
            except TelegramError:
                # If edit fails, try to send a new message
                await query.message.reply_text(f"⚠️ Ошибка обработки: {str(e)}")

    async def _handle_approve(self, query, news_id: str, data_entry: dict, context: ContextTypes.DEFAULT_TYPE):
        """Handle news approval and publication."""
        try:
            news_item = data_entry["news_data"]
            channel_id = data_entry["channel_id"]
            message_id = data_entry["message_id"]

            edit_status = " (отредактированной)" if news_item.get("edited", False) else ""

            # Publish to main channel
            success = await self.telegram.publish_news(context.bot, news_item, news_id)

            if success:
                # Clean up preview messages if they exist
                await self._cleanup_preview_messages(news_item, context.bot, news_id)

                # Delete moderation message
                await self.telegram.safe_delete_messages(
                    context.bot, channel_id, [message_id], news_id
                )

                # Update database
                self.db.update_news(news_id, {"status": "published"})

                # Send confirmation
                try:
                    await query.message.reply_text(
                        f"✅ Новость {news_id} успешно опубликована{edit_status}!"
                    )
                except Exception:
                    pass  # Not critical if confirmation fails

                # Remove from database after successful publication
                self.db.delete_news(news_id)

                logger.info(f"News {news_id} approved and published{edit_status}")

            else:
                await query.edit_message_text("❌ Ошибка при публикации новости.")

        except Exception as e:
            logger.error(f"Approve handler error for {news_id}: {e}")
            await query.edit_message_text(f"❌ Ошибка публикации: {str(e)}")

    async def _handle_reject(self, query, news_id: str, data_entry: dict, context: ContextTypes.DEFAULT_TYPE):
        """Handle news rejection and cleanup."""
        try:
            news_item = data_entry["news_data"]
            channel_id = data_entry["channel_id"]
            message_id = data_entry["message_id"]

            # Clean up preview messages if they exist
            await self._cleanup_preview_messages(news_item, context.bot, news_id)

            # Delete moderation message
            await self.telegram.safe_delete_messages(
                context.bot, channel_id, [message_id], news_id
            )

            # Update database
            self.db.update_news(news_id, {"status": "rejected"})

            # Send confirmation
            try:
                await query.message.reply_text(f"❌ Новость {news_id} отклонена и удалена.")
            except Exception:
                pass

            # Remove from database
            self.db.delete_news(news_id)

            logger.info(f"News {news_id} rejected and removed")

        except Exception as e:
            logger.error(f"Reject handler error for {news_id}: {e}")
            await query.edit_message_text(f"❌ Ошибка отклонения: {str(e)}")

    async def _handle_edit(self, query, news_id: str, data_entry: dict, context: ContextTypes.DEFAULT_TYPE):
        """Handle edit request - show full text and prepare for editing."""
        try:
            news_item = data_entry["news_data"]
            full_text = news_item.get("full_text", "")

            if full_text:
                # Send header message
                header_msg = await query.message.reply_text(
                    f"📝 Текущий полный текст новости (ID: {news_id}):"
                )

                # Send full text in chunks
                text_message_ids = await self.telegram.split_and_send_message(
                    context.bot, query.message.chat_id, full_text
                )

                # Store preview message IDs
                all_preview_ids = [header_msg.message_id] + text_message_ids

                # Update news data with preview info
                updates = {
                    "news_data.preview_message_ids": all_preview_ids,
                    "news_data.preview_chat_id": query.message.chat_id
                }
                self.db.update_news(news_id, updates)

                logger.info(f"Preview messages sent for news {news_id}: {all_preview_ids}")

            else:
                # No full text available
                preview_msg = await query.message.reply_text("⚠️ Полный текст новости отсутствует.")

                updates = {
                    "news_data.preview_message_ids": [preview_msg.message_id],
                    "news_data.preview_chat_id": query.message.chat_id
                }
                self.db.update_news(news_id, updates)

            # Send edit instructions
            await query.message.reply_text(
                "✏️ Отправьте исправленный текст новости.\n"
                "Чтобы оставить как есть — отправьте /skip\n"
                "⚠️ После редактирования сообщение в канале модерации будет обновлено."
            )

            # Set editing state
            if context.user_data is not None:
                context.user_data["editing_news_id"] = news_id

        except Exception as e:
            logger.error(f"Edit handler error for {news_id}: {e}")
            await query.edit_message_text(f"❌ Ошибка подготовки к редактированию: {str(e)}")

    async def _cleanup_preview_messages(self, news_item: dict, bot, news_id: str):
        """Clean up preview messages if they exist."""
        preview_ids = news_item.get("preview_message_ids")
        preview_chat_id = news_item.get("preview_chat_id")

        if preview_ids and preview_chat_id:
            await self.telegram.safe_delete_messages(
                bot, preview_chat_id, preview_ids, news_id
            )
            logger.info(f"Cleaned up preview messages for news {news_id}")


# bot/handlers/message_handlers.py
import logging
from telegram import Update
from telegram.ext import ContextTypes

from bot.database import SafeNewsDB
from bot.services.telegram_service import TelegramService

logger = logging.getLogger(__name__)


class MessageHandlers:
    """Handlers for text messages."""

    def __init__(self, database: SafeNewsDB, telegram_service: TelegramService):
        self.db = database
        self.telegram = telegram_service

    async def edit_text_handler(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle text messages for news editing."""
        if not update.message or not update.message.text:
            return

        logger.debug(f"Received text message: {update.message.text[:100]}...")

        # Check if user data exists and has editing state
        if not context.user_data:
            logger.debug("No user data available")
            return

        news_id = context.user_data.get("editing_news_id")
        if not news_id:
            logger.debug("No active editing session")
            return

        try:
            # Handle skip command
            if update.message.text.strip() == "/skip":
                await self._handle_skip_edit(update, context, news_id)
                return

            # Process the edited text
            await self._process_edited_text(update, context, news_id)

        except Exception as e:
            logger.error(f"Edit text handler error: {e}", exc_info=True)
            await update.message.reply_text(f"⚠️ Ошибка обработки текста: {str(e)}")
            # Clear editing state on error
            context.user_data["editing_news_id"] = None

    async def _handle_skip_edit(self, update: Update, context: ContextTypes.DEFAULT_TYPE, news_id: str):
        """Handle skip editing command."""
        context.user_data["editing_news_id"] = None
        await update.message.reply_text("✅ Редактирование пропущено.")
        logger.info(f"Editing skipped for news {news_id}")

    async def _process_edited_text(self, update: Update, context: ContextTypes.DEFAULT_TYPE, news_id: str):
        """Process the edited text for a news item."""
        new_text = update.message.text.strip()

        # Get news data
        data_entry = self.db.get_news(news_id)
        if not data_entry:
            await update.message.reply_text("⚠️ Новость не найдена в базе.")
            context.user_data["editing_news_id"] = None
            return

        # Update news data
        updates = {
            "news_data.full_text": new_text,
            "news_data.edited": True,
            "updated_at": None  # Will be set automatically by database
        }

        # Clean up old preview messages
        news_item = data_entry["news_data"]
        preview_ids = news_item.get("preview_message_ids")
        preview_chat_id = news_item.get("preview_chat_id")

        if preview_ids and preview_chat_id:
            await self.telegram.safe_delete_messages(
                context.bot, preview_chat_id, preview_ids, news_id
            )

            # Clear preview info
            updates.update({
                "news_data.preview_message_ids": [],
                "news_data.preview_chat_id": None
            })

        # Save changes
        success = self.db.update_news(news_id, updates)

        if not success:
            await update.message.reply_text("⚠️ Не удалось обновить новость.")
            context.user_data["editing_news_id"] = None
            return

        # Update moderation message
        channel_id = data_entry["channel_id"]
        message_id = data_entry["message_id"]

        if message_id:
            # Get updated news data
            updated_entry = self.db.get_news(news_id)
            updated_news_item = updated_entry["news_data"] if updated_entry else news_item

            success = await self.telegram.update_moderation_message(
                context.bot, channel_id, message_id, updated_news_item, news_id
            )

            if success:
                await update.message.reply_text(
                    "✅ Текст новости обновлён и сообщение в канале модерации обновлено!\n"
                    "Теперь нажмите кнопку 'Опубликовать' для публикации отредактированной версии."
                )
            else:
                await update.message.reply_text(
                    "✅ Текст новости обновлён!\n"
                    "⚠️ Не удалось обновить сообщение в канале модерации, но изменения сохранены.\n"
                    "Нажмите кнопку 'Опубликовать' для публикации отредактированной версии."
                )
        else:
            await update.message.reply_text(
                "✅ Текст новости обновлён!\n"
                "⚠️ Сообщение в канале модерации не найдено, но изменения сохранены."
            )

        # Clear editing state
        context.user_data["editing_news_id"] = None
        logger.info(f"News {news_id} text updated successfully")


# bot/handlers/command_handlers.py
import logging
from telegram import Update
from telegram.ext import ContextTypes

from bot.database import SafeNewsDB
from bot.services.telegram_service import TelegramService

logger = logging.getLogger(__name__)


class CommandHandlers:
    """Handlers for bot commands."""

    def __init__(self, database: SafeNewsDB, telegram_service: TelegramService):
        self.db = database
        self.telegram = telegram_service

    async def start_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle /start command."""
        welcome_text = (
            "🤖 Бот модерации энергетических новостей запущен!\n\n"
            "Доступные команды:\n"
            "/help - Показать справку\n"
            "/stats - Показать статистику\n"
            "/health - Проверить состояние системы\n"
            "/testpublish - Тест публикации в канал"
        )

        await update.message.reply_text(welcome_text)
        logger.info(f"Start command from user {update.effective_user.id}")

    async def help_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle /help command."""
        help_text = (
            "📖 Справка по боту модерации новостей\n\n"
            "🔧 Команды:\n"
            "/start - Запуск бота\n"
            "/help - Эта справка\n"
            "/stats - Статистика базы данных\n"
            "/health - Состояние системы\n"
            "/testpublish - Тестовая публикация\n"
            "/skip - Пропустить редактирование\n\n"
            "📝 Процесс модерации:\n"
            "1. Новости автоматически отправляются в канал модерации\n"
            "2. Используйте кнопки: ✅ Опубликовать, ❌ Отклонить, ✏️ Редактировать\n"
            "3. При редактировании отправьте новый текст или /skip\n\n"
            "⚠️ Все действия логируются для анализа."
        )

        await update.message.reply_text(help_text)

    async def stats_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle /stats command."""
        try:
            db_stats = self.db.get_stats()
            telegram_stats = self.telegram.get_circuit_breaker_stats()

            stats_text = (
                f"📊 Статистика системы\n\n"
                f"📰 База данных:\n"
                f"• Всего новостей: {db_stats['total_news']}\n"
                f"• Отправлено: {db_stats['sent_count']}\n"
                f"• Ожидает модерации: {db_stats['pending']}\n"
                f"• Опубликовано: {db_stats['published']}\n"
                f"• Отклонено: {db_stats['rejected']}\n"
                f"• Размер БД: {db_stats['db_size_mb']:.2f} МБ\n\n"
                f"📡 Telegram API:\n"
                f"• Статус: {telegram_stats['state']}\n"
                f"• Успешных запросов: {telegram_stats['success_count']}\n"
                f"• Неудачных запросов: {telegram_stats['failure_count']}\n"
                f"• Успешность: {telegram_stats['success_rate']:.1f}%"
            )

            await update.message.reply_text(stats_text)

        except Exception as e:
            logger.error(f"Stats command error: {e}")
            await update.message.reply_text(f"⚠️ Ошибка получения статистики: {str(e)}")

    async def health_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle /health command."""
        try:
            health_info = await self.telegram.health_check(context.bot)

            status_emoji = "🟢" if health_info["telegram_api"] == "healthy" else "🔴"

            health_text = (
                f"🏥 Состояние системы\n\n"
                f"{status_emoji} Telegram API: {health_info['telegram_api']}\n"
                f"🔌 Circuit Breaker: {health_info['circuit_breaker']}\n"
                f"💾 Размер кеша: {health_info['cache_size']}\n"
            )

            if "bot_username" in health_info:
                health_text += f"🤖 Бот: @{health_info['bot_username']}\n"

            if "error" in health_info:
                health_text += f"❌ Ошибка: {health_info['error']}\n"

            await update.message.reply_text(health_text)

        except Exception as e:
            logger.error(f"Health command error: {e}")
            await update.message.reply_text(f"⚠️ Ошибка проверки состояния: {str(e)}")

    async def test_publish_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle /testpublish command."""
        try:
            test_message = await self.telegram.send_with_retry(
                context.bot,
                self.telegram.config.publish_channel,
                "🔔 Тестовое сообщение от бота модерации"
            )

            if test_message:
                await update.message.reply_text("✅ Тестовое сообщение успешно отправлено в канал публикации.")
            else:
                await update.message.reply_text("❌ Не удалось отправить тестовое сообщение.")

        except Exception as e:
            logger.error(f"Test publish error: {e}")
            await update.message.reply_text(f"⚠️ Ошибка при тестовой публикации: {str(e)}")

    async def skip_edit_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle /skip command."""
        if not context.user_data:
            await update.message.reply_text("ℹ️ Нет активного процесса редактирования.")
            return

        news_id = context.user_data.get("editing_news_id")
        if news_id:
            context.user_data["editing_news_id"] = None
            await update.message.reply_text("✅ Редактирование пропущено.")
            logger.info(f"Editing skipped for news {news_id}")
        else:
            await update.message.reply_text("ℹ️ Нет активного процесса редактирования.")

    # Admin commands (only if debug mode is enabled)
    async def cleanup_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle /cleanup command (admin only)."""
        try:
            removed_count = self.db.cleanup_old_news(days=30)
            await update.message.reply_text(f"🗑️ Очищено {removed_count} старых новостей.")

        except Exception as e:
            logger.error(f"Cleanup command error: {e}")
            await update.message.reply_text(f"⚠️ Ошибка очистки: {str(e)}")

    async def backup_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle /backup command (admin only)."""
        try:
            self.db.force_save()
            await update.message.reply_text("💾 Принудительное сохранение базы данных выполнено.")

        except Exception as e:
            logger.error(f"Backup command error: {e}")
            await update.message.reply_text(f"⚠️ Ошибка сохранения: {str(e)}")
===== C:\Users\SK-GROUP\PycharmProjects\PythonProject\energy_news_project\bot\handlers\command_handlers.py =====
# bot/handlers/command_handlers.py
import logging
from telegram import Update
from telegram.ext import ContextTypes

logger = logging.getLogger(__name__)


class CommandHandlers:
    """Handlers for bot commands."""

    def __init__(self, database, telegram_service):
        self.db = database
        self.telegram = telegram_service

    async def start_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle /start command."""
        welcome_text = (
            "🤖 Бот модерации энергетических новостей запущен!\n\n"
            "Доступные команды:\n"
            "/help - Показать справку\n"
            "/stats - Показать статистику\n"
            "/health - Проверить состояние системы\n"
            "/testpublish - Тест публикации в канал"
        )

        await update.message.reply_text(welcome_text)
        logger.info(f"Start command from user {update.effective_user.id}")

    async def help_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle /help command."""
        help_text = (
            "📖 Справка по боту модерации новостей\n\n"
            "🔧 Команды:\n"
            "/start - Запуск бота\n"
            "/help - Эта справка\n"
            "/stats - Статистика базы данных\n"
            "/health - Состояние системы\n"
            "/testpublish - Тестовая публикация\n"
            "/skip - Пропустить редактирование\n\n"
            "📝 Процесс модерации:\n"
            "1. Новости автоматически отправляются в канал модерации\n"
            "2. Используйте кнопки: ✅ Опубликовать, ❌ Отклонить, ✏️ Редактировать\n"
            "3. При редактировании отправьте новый текст или /skip\n\n"
            "⚠️ Все действия логируются для анализа."
        )

        await update.message.reply_text(help_text)

    async def stats_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle /stats command."""
        try:
            # Basic stats from database
            total_news = len(self.db.news_db) if hasattr(self.db, 'news_db') else 0
            sent_count = len(self.db.sent_ids) if hasattr(self.db, 'sent_ids') else 0

            stats_text = (
                f"📊 Статистика системы\n\n"
                f"📰 База данных:\n"
                f"• Всего новостей: {total_news}\n"
                f"• Отправлено: {sent_count}\n"
            )

            # Add telegram stats if available
            if hasattr(self.telegram, 'get_circuit_breaker_stats'):
                telegram_stats = self.telegram.get_circuit_breaker_stats()
                stats_text += (
                    f"\n📡 Telegram API:\n"
                    f"• Статус: {telegram_stats['state']}\n"
                    f"• Успешных запросов: {telegram_stats['success_count']}\n"
                    f"• Неудачных запросов: {telegram_stats['failure_count']}\n"
                    f"• Успешность: {telegram_stats['success_rate']:.1f}%"
                )

            await update.message.reply_text(stats_text)

        except Exception as e:
            logger.error(f"Stats command error: {e}")
            await update.message.reply_text(f"⚠️ Ошибка получения статистики: {str(e)}")

    async def health_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle /health command."""
        try:
            health_text = "🏥 Состояние системы\n\n"

            # Check bot connection
            try:
                bot_info = await context.bot.get_me()
                health_text += f"🟢 Telegram API: healthy\n"
                health_text += f"🤖 Бот: @{bot_info.username}\n"
            except Exception as e:
                health_text += f"🔴 Telegram API: unhealthy - {str(e)}\n"

            # Database status
            health_text += f"💾 База данных: активна\n"

            await update.message.reply_text(health_text)

        except Exception as e:
            logger.error(f"Health command error: {e}")
            await update.message.reply_text(f"⚠️ Ошибка проверки состояния: {str(e)}")

    async def test_publish_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle /testpublish command."""
        try:
            # Get publish channel from config or fallback
            publish_channel = getattr(self.telegram.config if hasattr(self.telegram, 'config') else None,
                                      'publish_channel', None)
            if not publish_channel:
                # Fallback to hardcoded value from original code
                publish_channel = "-1003006895565"

            await context.bot.send_message(
                chat_id=publish_channel,
                text="🔔 Тестовое сообщение от бота модерации"
            )

            await update.message.reply_text("✅ Тестовое сообщение успешно отправлено в канал публикации.")

        except Exception as e:
            logger.error(f"Test publish error: {e}")
            await update.message.reply_text(f"⚠️ Ошибка при тестовой публикации: {str(e)}")

    async def skip_edit_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle /skip command."""
        if not context.user_data:
            await update.message.reply_text("ℹ️ Нет активного процесса редактирования.")
            return

        news_id = context.user_data.get("editing_news_id")
        if news_id:
            context.user_data["editing_news_id"] = None
            await update.message.reply_text("✅ Редактирование пропущено.")
            logger.info(f"Editing skipped for news {news_id}")
        else:
            await update.message.reply_text("ℹ️ Нет активного процесса редактирования.")

    # Admin commands (optional)
    async def cleanup_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle /cleanup command (admin only)."""
        try:
            if hasattr(self.db, 'cleanup_old_news'):
                removed_count = self.db.cleanup_old_news(days=30)
                await update.message.reply_text(f"🗑️ Очищено {removed_count} старых новостей.")
            else:
                await update.message.reply_text("⚠️ Функция очистки недоступна.")

        except Exception as e:
            logger.error(f"Cleanup command error: {e}")
            await update.message.reply_text(f"⚠️ Ошибка очистки: {str(e)}")

    async def backup_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle /backup command (admin only)."""
        try:
            if hasattr(self.db, 'force_save'):
                self.db.force_save()
            elif hasattr(self.db, 'save_db'):
                self.db.save_db()
                if hasattr(self.db, 'save_sent_ids'):
                    self.db.save_sent_ids()

            await update.message.reply_text("💾 Принудительное сохранение базы данных выполнено.")

        except Exception as e:
            logger.error(f"Backup command error: {e}")
            await update.message.reply_text(f"⚠️ Ошибка сохранения: {str(e)}")
===== C:\Users\SK-GROUP\PycharmProjects\PythonProject\energy_news_project\bot\handlers\message_handlers.py =====
# bot/handlers/message_handlers.py
import logging
from telegram import Update
from telegram.ext import ContextTypes

logger = logging.getLogger(__name__)


class MessageHandlers:
    """Handlers for text messages."""

    def __init__(self, database, telegram_service):
        self.db = database
        self.telegram = telegram_service

    async def edit_text_handler(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle text messages for news editing."""
        if not update.message or not update.message.text:
            return

        logger.debug(f"Received text message: {update.message.text[:100]}...")

        # Check if user data exists and has editing state
        if not context.user_data:
            logger.debug("No user data available")
            return

        news_id = context.user_data.get("editing_news_id")
        if not news_id:
            logger.debug("No active editing session")
            return

        try:
            # Handle skip command
            if update.message.text.strip() == "/skip":
                await self._handle_skip_edit(update, context, news_id)
                return

            # Process the edited text
            await self._process_edited_text(update, context, news_id)

        except Exception as e:
            logger.error(f"Edit text handler error: {e}", exc_info=True)
            await update.message.reply_text(f"⚠️ Ошибка обработки текста: {str(e)}")
            # Clear editing state on error
            context.user_data["editing_news_id"] = None

    async def _handle_skip_edit(self, update: Update, context: ContextTypes.DEFAULT_TYPE, news_id: str):
        """Handle skip editing command."""
        context.user_data["editing_news_id"] = None
        await update.message.reply_text("✅ Редактирование пропущено.")
        logger.info(f"Editing skipped for news {news_id}")

    async def _process_edited_text(self, update: Update, context: ContextTypes.DEFAULT_TYPE, news_id: str):
        """Process the edited text for a news item."""
        new_text = update.message.text.strip()

        # Get news data
        data_entry = self.db.get_news(news_id)
        if not data_entry:
            await update.message.reply_text("⚠️ Новость не найдена в базе.")
            context.user_data["editing_news_id"] = None
            return

        # Update news data in database
        try:
            # Update the full text and mark as edited
            self.db.news_db[news_id]["news_data"]["full_text"] = new_text
            self.db.news_db[news_id]["news_data"]["edited"] = True

            # Clean up old preview messages if they exist
            news_item = data_entry["news_data"]
            preview_ids = news_item.get("preview_message_ids")
            preview_chat_id = news_item.get("preview_chat_id")

            if preview_ids and preview_chat_id:
                # Delete preview messages
                if hasattr(self.telegram, 'safe_delete_messages'):
                    await self.telegram.safe_delete_messages(
                        context.bot, preview_chat_id, preview_ids, news_id
                    )
                else:
                    # Fallback manual deletion
                    for msg_id in preview_ids:
                        try:
                            await context.bot.delete_message(chat_id=preview_chat_id, message_id=msg_id)
                        except Exception:
                            pass

                # Clear preview info
                self.db.news_db[news_id]["news_data"]["preview_message_ids"] = []
                self.db.news_db[news_id]["news_data"]["preview_chat_id"] = None

            # Save changes
            self.db.save_db()

        except Exception as e:
            logger.error(f"Error updating news {news_id}: {e}")
            await update.message.reply_text(f"⚠️ Ошибка сохранения изменений: {str(e)}")
            context.user_data["editing_news_id"] = None
            return

        # Update moderation message
        try:
            channel_id = data_entry["channel_id"]
            message_id = data_entry["message_id"]

            if message_id:
                # Get updated news item
                updated_news_item = self.db.news_db[news_id]["news_data"]

                # Format updated message
                def safe_escape_text(text):
                    if not text:
                        return ""
                    import re
                    text = re.sub(r'<[^>]+>', '', str(text))
                    text = re.sub(r'\s+', ' ', text).strip()
                    return text

                title = safe_escape_text(updated_news_item.get("title", ""))
                preview = safe_escape_text(updated_news_item.get("preview", ""))
                source = safe_escape_text(updated_news_item.get("source", ""))
                date = safe_escape_text(updated_news_item.get("date", ""))
                url = updated_news_item.get('url', '')

                updated_text = (
                    f"📰 {title} ✏️ ОТРЕДАКТИРОВАНО\n\n"
                    f"{preview}\n\n"
                    f"Источник: {source} ({date})\n"
                    f"{url}"
                )

                # Create new keyboard
                from telegram import InlineKeyboardButton, InlineKeyboardMarkup
                keyboard = [
                    [
                        InlineKeyboardButton("✅ Опубликовать", callback_data=f"approve|{news_id}"),
                        InlineKeyboardButton("❌ Отклонить", callback_data=f"reject|{news_id}"),
                        InlineKeyboardButton("✏️ Редактировать", callback_data=f"edit|{news_id}")
                    ]
                ]

                await context.bot.edit_message_text(
                    chat_id=channel_id,
                    message_id=message_id,
                    text=updated_text,
                    reply_markup=InlineKeyboardMarkup(keyboard),
                    disable_web_page_preview=True
                )

                await update.message.reply_text(
                    "✅ Текст новости обновлён и сообщение в канале модерации обновлено!\n"
                    "Теперь нажмите кнопку 'Опубликовать' для публикации отредактированной версии."
                )

            else:
                await update.message.reply_text(
                    "✅ Текст новости обновлён!\n"
                    "⚠️ Сообщение в канале модерации не найдено, но изменения сохранены."
                )

        except Exception as update_error:
            logger.error(f"Error updating moderation message: {update_error}")
            await update.message.reply_text(
                "✅ Текст новости обновлён!\n"
                "⚠️ Не удалось обновить сообщение в канале модерации, но изменения сохранены.\n"
                "Нажмите кнопку 'Опубликовать' для публикации отредактированной версии."
            )

        # Clear editing state
        context.user_data["editing_news_id"] = None
        logger.info(f"News {news_id} text updated successfully")
===== C:\Users\SK-GROUP\PycharmProjects\PythonProject\energy_news_project\bot\middleware\rate_limiter.py =====
# bot/middleware/rate_limiter.py
import time
import logging
from collections import defaultdict, deque
from typing import Dict, Optional
from telegram.ext import BaseRateLimiter
from telegram import Update

logger = logging.getLogger(__name__)


class RateLimiter(BaseRateLimiter):
    """Custom rate limiter with per-user and global limits."""

    def __init__(self,
                 global_rate: int = 30,  # requests per minute globally
                 user_rate: int = 10,  # requests per minute per user
                 window_size: int = 60):  # time window in seconds

        self.global_rate = global_rate
        self.user_rate = user_rate
        self.window_size = window_size

        # Storage for request timestamps
        self.global_requests: deque = deque()
        self.user_requests: Dict[int, deque] = defaultdict(lambda: deque())

        # Admin users (can be configured)
        self.admin_users = set()

    def add_admin_user(self, user_id: int):
        """Add admin user (no rate limiting)."""
        self.admin_users.add(user_id)
        logger.info(f"Added admin user: {user_id}")

    def _clean_old_requests(self, request_queue: deque, current_time: float):
        """Remove requests older than window_size."""
        while request_queue and current_time - request_queue[0] > self.window_size:
            request_queue.popleft()

    async def process_request(self,
                              callback,
                              update: Update,
                              application,
                              check_result=None) -> None:
        """Process request with rate limiting."""
        current_time = time.time()

        # Get user ID
        user_id = None
        if update.effective_user:
            user_id = update.effective_user.id

        # Skip rate limiting for admin users
        if user_id in self.admin_users:
            await callback()
            return

        # Clean old requests
        self._clean_old_requests(self.global_requests, current_time)
        if user_id:
            self._clean_old_requests(self.user_requests[user_id], current_time)

        # Check global rate limit
        if len(self.global_requests) >= self.global_rate:
            logger.warning(f"Global rate limit exceeded")
            if update.effective_message:
                await update.effective_message.reply_text(
                    "⏱️ Система перегружена. Попробуйте позже."
                )
            return

        # Check user rate limit
        if user_id and len(self.user_requests[user_id]) >= self.user_rate:
            logger.warning(f"User rate limit exceeded for user {user_id}")
            if update.effective_message:
                await update.effective_message.reply_text(
                    "⏱️ Слишком много запросов. Подождите минуту."
                )
            return

        # Record request
        self.global_requests.append(current_time)
        if user_id:
            self.user_requests[user_id].append(current_time)

        # Execute callback
        try:
            await callback()
        except Exception as e:
            logger.error(f"Callback execution error: {e}")
            raise

    def get_stats(self) -> Dict:
        """Get rate limiter statistics."""
        current_time = time.time()

        # Clean old requests first
        self._clean_old_requests(self.global_requests, current_time)

        active_users = 0
        for user_queue in self.user_requests.values():
            self._clean_old_requests(user_queue, current_time)
            if len(user_queue) > 0:
                active_users += 1

        return {
            "global_requests_current_window": len(self.global_requests),
            "global_rate_limit": self.global_rate,
            "user_rate_limit": self.user_rate,
            "active_users": active_users,
            "admin_users": len(self.admin_users),
            "window_size": self.window_size
        }
===== C:\Users\SK-GROUP\PycharmProjects\PythonProject\energy_news_project\bot\services\telegram_service.py =====
# bot/services/telegram_service.py
import asyncio
import hashlib
import logging
import time
from contextlib import asynccontextmanager
from enum import Enum
from typing import List, Optional, Dict, Any
from dataclasses import dataclass, field

from telegram import Bot, InlineKeyboardButton, InlineKeyboardMarkup, Message
from telegram.error import TelegramError, RetryAfter, TimedOut, NetworkError

from bot.formatters import format_news_for_publication
from config import TelegramConfig

logger = logging.getLogger(__name__)


class CircuitBreakerState(Enum):
    CLOSED = "closed"
    OPEN = "open"
    HALF_OPEN = "half_open"


@dataclass
class CircuitBreakerStats:
    failure_count: int = 0
    last_failure_time: float = 0
    success_count: int = 0
    total_requests: int = 0
    state_changes: List[tuple] = field(default_factory=list)


class CircuitBreaker:
    """Circuit breaker for handling service failures gracefully."""

    def __init__(self, failure_threshold: int = 5, recovery_timeout: float = 60.0,
                 expected_exception: type = TelegramError):
        self.failure_threshold = failure_threshold
        self.recovery_timeout = recovery_timeout
        self.expected_exception = expected_exception

        self.state = CircuitBreakerState.CLOSED
        self.stats = CircuitBreakerStats()

    def _change_state(self, new_state: CircuitBreakerState, reason: str = ""):
        old_state = self.state
        self.state = new_state
        timestamp = time.time()
        self.stats.state_changes.append((timestamp, old_state.value, new_state.value, reason))
        logger.info(f"Circuit breaker state changed: {old_state.value} -> {new_state.value} ({reason})")

    def _should_attempt_reset(self) -> bool:
        return (
                self.state == CircuitBreakerState.OPEN and
                time.time() - self.stats.last_failure_time > self.recovery_timeout
        )

    async def call(self, func, *args, **kwargs):
        """Execute function with circuit breaker protection."""
        self.stats.total_requests += 1

        if self.state == CircuitBreakerState.OPEN:
            if self._should_attempt_reset():
                self._change_state(CircuitBreakerState.HALF_OPEN, "recovery timeout reached")
            else:
                raise TelegramError("Circuit breaker is OPEN")

        try:
            result = await func(*args, **kwargs)

            # Success
            if self.state == CircuitBreakerState.HALF_OPEN:
                self._change_state(CircuitBreakerState.CLOSED, "successful call in half-open state")
                self.stats.failure_count = 0

            self.stats.success_count += 1
            return result

        except self.expected_exception as e:
            self.stats.failure_count += 1
            self.stats.last_failure_time = time.time()

            if (self.state == CircuitBreakerState.CLOSED and
                    self.stats.failure_count >= self.failure_threshold):
                self._change_state(CircuitBreakerState.OPEN, f"failure threshold reached ({self.stats.failure_count})")
            elif self.state == CircuitBreakerState.HALF_OPEN:
                self._change_state(CircuitBreakerState.OPEN, "failure in half-open state")

            raise


class TelegramService:
    """Enhanced Telegram service with reliability features."""

    def __init__(self, config: TelegramConfig):
        self.config = config
        self.circuit_breaker = CircuitBreaker()
        self._message_cache: Dict[str, int] = {}  # Cache for deduplication

    def make_news_id(self, item: dict, index: int = 0) -> str:
        """Generate unique ID for news item."""
        key = (item.get("url") or "").strip()
        if not key:
            key = f"{item.get('title', '')}-{item.get('date', '')}".strip()
        if not key:
            key = item.get("preview", "")[:120]

        return hashlib.sha256(key.encode("utf-8")).hexdigest()[:16]

    async def send_with_retry(self, bot: Bot, chat_id: str, text: str,
                              reply_markup: Optional[InlineKeyboardMarkup] = None,
                              **kwargs) -> Optional[Message]:
        """Send message with exponential backoff retry logic."""

        # Check for duplicate messages
        message_hash = hashlib.md5(f"{chat_id}:{text}".encode()).hexdigest()
        if message_hash in self._message_cache:
            recent_time = time.time() - self._message_cache[message_hash]
            if recent_time < 60:  # Prevent duplicates within 1 minute
                logger.warning(f"Duplicate message detected, skipping: {text[:50]}...")
                return None

        async def _send():
            return await bot.send_message(
                chat_id=chat_id,
                text=text,
                reply_markup=reply_markup,
                disable_web_page_preview=True,
                **kwargs
            )

        for attempt in range(self.config.retry_attempts):
            try:
                message = await self.circuit_breaker.call(_send)

                if message:
                    self._message_cache[message_hash] = time.time()
                    # Clean old cache entries
                    if len(self._message_cache) > 1000:
                        current_time = time.time()
                        self._message_cache = {
                            k: v for k, v in self._message_cache.items()
                            if current_time - v < 3600  # Keep only last hour
                        }

                await asyncio.sleep(self.config.flood_control_delay)
                return message

            except RetryAfter as e:
                wait_time = e.retry_after + 1
                logger.warning(f"Rate limited, waiting {wait_time} seconds...")
                await asyncio.sleep(wait_time)

            except (TimedOut, NetworkError) as e:
                wait_time = min(2 ** attempt, 60)  # Exponential backoff, max 60s
                logger.warning(f"Network error on attempt {attempt + 1}: {e}. Retrying in {wait_time}s...")
                await asyncio.sleep(wait_time)

            except TelegramError as e:
                logger.error(f"Telegram error on attempt {attempt + 1}: {e}")
                if "Bad Request" in str(e):  # Don't retry bad requests
                    break
                await asyncio.sleep(2 ** attempt)

            except Exception as e:
                logger.error(f"Unexpected error on attempt {attempt + 1}: {e}")
                await asyncio.sleep(2 ** attempt)

        logger.error(f"Failed to send message after {self.config.retry_attempts} attempts")
        return None

    async def split_and_send_message(self, bot: Bot, chat_id: str, text: str,
                                     max_length: int = None) -> List[int]:
        """Split long text and send as multiple messages."""
        if max_length is None:
            max_length = self.config.max_message_length

        message_ids = []

        if len(text) <= max_length:
            message = await self.send_with_retry(bot, chat_id, text)
            if message:
                message_ids.append(message.message_id)
            return message_ids

        # Smart splitting by sentences
        sentences = text.split('. ')
        current_chunk = ""

        for sentence in sentences:
            if len(current_chunk + sentence + '. ') <= max_length:
                current_chunk += sentence + '. '
            else:
                if current_chunk:
                    message = await self.send_with_retry(bot, chat_id, current_chunk.strip())
                    if message:
                        message_ids.append(message.message_id)
                    current_chunk = sentence + '. '
                else:
                    # Handle very long sentences
                    while len(sentence) > max_length:
                        chunk = sentence[:max_length]
                        message = await self.send_with_retry(bot, chat_id, chunk)
                        if message:
                            message_ids.append(message.message_id)
                        sentence = sentence[max_length:]
                    current_chunk = sentence + '. ' if sentence else ""

        # Send remaining text
        if current_chunk:
            message = await self.send_with_retry(bot, chat_id, current_chunk.strip())
            if message:
                message_ids.append(message.message_id)

        return message_ids

    async def safe_delete_messages(self, bot: Bot, chat_id: str,
                                   message_ids: List[int], news_id: str = "") -> int:
        """Safely delete multiple messages."""
        if not message_ids:
            return 0

        deleted_count = 0
        for message_id in message_ids:
            if message_id is None:
                continue

            try:
                await bot.delete_message(chat_id=chat_id, message_id=message_id)
                deleted_count += 1
                await asyncio.sleep(0.1)  # Small delay between deletions

            except TelegramError as e:
                logger.warning(f"Failed to delete message {message_id} for news {news_id}: {e}")
            except Exception as e:
                logger.error(f"Unexpected error deleting message {message_id}: {e}")

        logger.info(f"Deleted {deleted_count}/{len(message_ids)} messages for news {news_id}")
        return deleted_count

    def create_moderation_keyboard(self, news_id: str) -> InlineKeyboardMarkup:
        """Create keyboard for news moderation."""
        keyboard = [
            [
                InlineKeyboardButton("✅ Опубликовать", callback_data=f"approve|{news_id}"),
                InlineKeyboardButton("❌ Отклонить", callback_data=f"reject|{news_id}"),
                InlineKeyboardButton("✏️ Редактировать", callback_data=f"edit|{news_id}")
            ]
        ]
        return InlineKeyboardMarkup(keyboard)

    def safe_escape_text(self, text: str) -> str:
        """Safely escape text for Telegram."""
        if not text:
            return ""

        # Remove HTML tags
        import re
        text = re.sub(r'<[^>]+>', '', str(text))

        # Clean multiple whitespaces
        text = re.sub(r'\s+', ' ', text).strip()

        return text

    def format_moderation_message(self, news_item: dict, news_id: str, edited: bool = False) -> str:
        """Format news item for moderation channel."""
        title = self.safe_escape_text(news_item.get("title", "Без заголовка"))
        preview = self.safe_escape_text(news_item.get("preview", ""))
        source = self.safe_escape_text(news_item.get("source", "Источник не указан"))
        date = self.safe_escape_text(news_item.get("date", ""))
        url = news_item.get("url", "")

        edit_marker = " ✏️ ОТРЕДАКТИРОВАНО" if edited else ""

        return (
            f"📰 {title}{edit_marker}\n\n"
            f"{preview}\n\n"
            f"Источник: {source} ({date})\n"
            f"{url}"
        )

    async def send_to_moderation(self, bot: Bot, news_item: dict, news_id: str) -> Optional[Message]:
        """Send news to moderation channel."""
        try:
            text = self.format_moderation_message(news_item, news_id)
            keyboard = self.create_moderation_keyboard(news_id)

            message = await self.send_with_retry(
                bot,
                self.config.moderation_channel,
                text,
                reply_markup=keyboard
            )

            if message:
                logger.info(f"News {news_id} sent to moderation (message_id={message.message_id})")
            else:
                logger.error(f"Failed to send news {news_id} to moderation")

            return message

        except Exception as e:
            logger.error(f"Error sending news {news_id} to moderation: {e}")
            return None

    async def publish_news(self, bot: Bot, news_item: dict, news_id: str) -> bool:
        """Publish news to the main channel."""
        try:
            publication_text = format_news_for_publication(news_item)

            message = await self.send_with_retry(
                bot,
                self.config.publish_channel,
                publication_text
            )

            if message:
                logger.info(f"News {news_id} published successfully")
                return True
            else:
                logger.error(f"Failed to publish news {news_id}")
                return False

        except Exception as e:
            logger.error(f"Error publishing news {news_id}: {e}")
            return False

    async def update_moderation_message(self, bot: Bot, chat_id: str, message_id: int,
                                        news_item: dict, news_id: str) -> bool:
        """Update moderation message after editing."""
        try:
            updated_text = self.format_moderation_message(news_item, news_id, edited=True)
            keyboard = self.create_moderation_keyboard(news_id)

            await bot.edit_message_text(
                chat_id=chat_id,
                message_id=message_id,
                text=updated_text,
                reply_markup=keyboard,
                disable_web_page_preview=True
            )

            logger.info(f"Moderation message updated for news {news_id}")
            return True

        except TelegramError as e:
            logger.error(f"Failed to update moderation message for news {news_id}: {e}")
            return False

    def get_circuit_breaker_stats(self) -> dict:
        """Get circuit breaker statistics."""
        stats = self.circuit_breaker.stats
        return {
            "state": self.circuit_breaker.state.value,
            "failure_count": stats.failure_count,
            "success_count": stats.success_count,
            "total_requests": stats.total_requests,
            "last_failure_time": stats.last_failure_time,
            "success_rate": (stats.success_count / max(stats.total_requests, 1)) * 100
        }

    async def health_check(self, bot: Bot) -> dict:
        """Perform health check on Telegram service."""
        health_info = {
            "telegram_api": "unknown",
            "circuit_breaker": self.circuit_breaker.state.value,
            "cache_size": len(self._message_cache)
        }

        try:
            # Test API connectivity
            bot_info = await bot.get_me()
            health_info["telegram_api"] = "healthy"
            health_info["bot_username"] = bot_info.username

        except Exception as e:
            health_info["telegram_api"] = "unhealthy"
            health_info["error"] = str(e)

        return health_info
===== C:\Users\SK-GROUP\PycharmProjects\PythonProject\energy_news_project\bot\bot_runner_simple.py =====
# bot/bot_runner_simple.py
import asyncio
import logging
import sys
import os
from telegram.ext import (
    Application, CommandHandler, CallbackQueryHandler,
    MessageHandler, filters, ContextTypes
)
from telegram.constants import ChatType

# Create logs directory
os.makedirs("logs", exist_ok=True)

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("logs/bot.log", encoding="utf-8"),
        logging.FileHandler("logs/errors.log", encoding="utf-8", mode='a'),
        logging.StreamHandler(sys.stdout)
    ]
)

# Filter for error log
error_handler = logging.FileHandler("logs/errors.log", encoding="utf-8")
error_handler.setLevel(logging.ERROR)
logging.getLogger().addHandler(error_handler)

logger = logging.getLogger(__name__)

# Import your existing modules
try:
    from bot.database import SafeNewsDB

    NEW_DATABASE = True
    logger.info("Using new SafeNewsDB")
except ImportError:
    from bot.db import NewsDB as SafeNewsDB

    NEW_DATABASE = False
    logger.info("Using legacy NewsDB")

from bot.cli import load_and_send_news

# Load environment variables
from dotenv import load_dotenv

load_dotenv()

# Configuration
TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "8217915867:AAFLPnQmnxhHmjloF4Ct3HhR9jjRjVYV6C8")
MODERATION_CHANNEL = os.getenv("MODERATION_CHANNEL", "-1002996332660")
PUBLISH_CHANNEL = os.getenv("PUBLISH_CHANNEL", "-1003006895565")

if not TOKEN:
    logger.error("TELEGRAM_BOT_TOKEN not found!")
    sys.exit(1)

# Initialize database
if NEW_DATABASE:
    db = SafeNewsDB()
else:
    db = NewsDB()
if NEW_DATABASE:
    db = SafeNewsDB()
else:
    db = SafeNewsDB()

# Import handlers
from bot.telegram_handlers import button_handler, edit_text_handler, skip_edit_handler


# Simple command handlers
async def start(update, context):
    await update.message.reply_text(
        "🤖 Бот модерации энергетических новостей запущен!\n\n"
        "Доступные команды:\n"
        "/help - Показать справку\n"
        "/stats - Показать статистику\n"
        "/testpublish - Тест публикации в канал"
    )


async def help_command(update, context):
    help_text = (
        "📖 Справка по боту модерации новостей\n\n"
        "🔧 Команды:\n"
        "/start - Запуск бота\n"
        "/help - Эта справка\n"
        "/stats - Статистика базы данных\n"
        "/testpublish - Тестовая публикация\n"
        "/skip - Пропустить редактирование\n\n"
        "📝 Процесс модерации:\n"
        "1. Новости автоматически отправляются в канал модерации\n"
        "2. Используйте кнопки: ✅ Опубликовать, ❌ Отклонить, ✏️ Редактировать\n"
        "3. При редактировании отправьте новый текст или /skip\n\n"
        "⚠️ Все действия логируются для анализа."
    )
    await update.message.reply_text(help_text)


async def stats_command(update, context):
    try:
        if hasattr(db, 'get_stats'):
            stats = db.get_stats()
            stats_text = (
                f"📊 Статистика системы\n\n"
                f"📰 База данных:\n"
                f"• Всего новостей: {stats.get('total_news', 0)}\n"
                f"• Отправлено: {stats.get('sent_count', 0)}\n"
            )
        else:
            # Legacy database
            total_news = len(db.news_db) if hasattr(db, 'news_db') else 0
            sent_count = len(db.sent_ids) if hasattr(db, 'sent_ids') else 0
            stats_text = (
                f"📊 Статистика системы\n\n"
                f"📰 База данных:\n"
                f"• Всего новостей: {total_news}\n"
                f"• Отправлено: {sent_count}\n"
            )

        await update.message.reply_text(stats_text)
    except Exception as e:
        logger.error(f"Stats error: {e}")
        await update.message.reply_text(f"⚠️ Ошибка получения статистики: {str(e)}")


async def test_publish_command(update, context):
    try:
        await context.bot.send_message(
            chat_id=PUBLISH_CHANNEL,
            text="🔔 Тестовая публикация"
        )
        await update.message.reply_text("✅ Отправлено (если бот имеет доступ к каналу).")
    except Exception as e:
        await update.message.reply_text(f"⚠️ Ошибка при публикации: {e}")


async def error_handler(update: object, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Log errors caused by Updates."""
    logger.error("Exception while handling an update:", exc_info=context.error)


async def post_init(app):
    try:
        await app.bot.delete_webhook(drop_pending_updates=True)
    except Exception as e:
        logger.warning(f"Не удалось удалить webhook: {e}")

    # Запуск консольного меню в отдельной таске
    asyncio.create_task(load_and_send_news(db, app.bot))


def run_bot():
    logger.info("Starting Telegram News Bot")

    application = Application.builder().token(TOKEN).post_init(post_init).build()

    # Command handlers
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("stats", stats_command))
    application.add_handler(CommandHandler("testpublish", test_publish_command))
    application.add_handler(CommandHandler("skip", skip_edit_handler))

    # Callback handlers
    application.add_handler(CallbackQueryHandler(
        lambda u, c: button_handler(u, c, db),
        pattern=r"^(approve|reject|edit)\|"
    ))

    # Message handlers
    application.add_handler(MessageHandler(
        filters.TEXT & ~filters.COMMAND & filters.ChatType.PRIVATE,
        lambda u, c: edit_text_handler(u, c, db)
    ))

    # Error handler
    application.add_error_handler(error_handler)

    logger.info("Bot starting...")

    try:
        application.run_polling(
            drop_pending_updates=True,
            close_loop=False  # Don't close the event loop
        )
    except KeyboardInterrupt:
        logger.info("Bot stopped by user")
    except Exception as e:
        logger.error(f"Bot runtime error: {e}")
    finally:
        # Cleanup
        logger.info("Shutting down...")
        if hasattr(db, 'force_save'):
            try:
                db.force_save()
                logger.info("Database saved before shutdown")
            except Exception as e:
                logger.error(f"Error saving database: {e}")


if __name__ == "__main__":
    run_bot()
===== C:\Users\SK-GROUP\PycharmProjects\PythonProject\energy_news_project\bot\cli.py =====
# bot/cli.py
import os
import json
import asyncio
from typing import Union

# Try to import the new database first, fallback to old one
try:
    from bot.database import SafeNewsDB as NewsDB
except ImportError:
    from bot.database import SafeNewsDB

from bot.telegram_bot import send_to_moderation, make_news_id

DATA_DIR = "data"


async def safe_input(prompt):
    """Безопасный ввод с обработкой кодировки"""
    try:
        return (await asyncio.to_thread(input, prompt)).strip()
    except UnicodeDecodeError:
        print("⚠️ Ошибка кодировки. Попробуйте еще раз.")
        return ""
    except Exception as e:
        print(f"⚠️ Ошибка ввода: {e}")
        return ""


async def load_and_send_news(db: Union[NewsDB, "SafeNewsDB"], bot):
    """
    Консольное меню для загрузки новостей и отправки их в модерацию.
    """
    while True:
        print("\nВыберите действие:")
        print("1) Загрузить новые новости из последнего файла energy_news*.json")
        print("2) Загрузить новости из выбранного файла")
        print("3) Показать количество новостей в базе")
        print("4) Очистить NEWS_DB и sent_ids.json")
        print("5) Очистить поврежденные записи (без message_id)")
        print("0) Выход")

        choice = await safe_input("Введите пункт меню: ")

        if not choice:  # Если ввод пустой из-за ошибки
            continue

        # --- 1) Последний файл ---
        if choice == "1":
            files = [os.path.join(DATA_DIR, f) for f in os.listdir(DATA_DIR)
                     if f.startswith("energy_news") and f.endswith(".json")]
            latest_file = max(files, key=os.path.getctime) if files else None

            if not latest_file:
                print("❗ Нет файлов energy_news*.json")
                continue

            try:
                with open(latest_file, "r", encoding="utf-8") as f:
                    news_list = json.load(f)
                print(f"📂 Загружено {len(news_list)} новостей из {os.path.basename(latest_file)}")
            except Exception as e:
                print(f"❗ Ошибка чтения файла {latest_file}: {e}")
                continue

        # --- 2) Выбранный файл ---
        elif choice == "2":
            file_name = await safe_input("Введите имя файла в папке data/: ")
            if not file_name:
                continue

            file_path = os.path.join(DATA_DIR, file_name)
            if not os.path.exists(file_path):
                print("❗ Файл не найден")
                continue

            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    news_list = json.load(f)
                print(f"📂 Загружено {len(news_list)} новостей из {file_name}")
            except Exception as e:
                print(f"❗ Ошибка чтения файла {file_path}: {e}")
                continue

        # --- 3) Количество новостей ---
        elif choice == "3":
            # Handle both old and new database formats
            if hasattr(db, 'news_db'):
                print(f"📊 В базе {len(db.news_db)} новостей.")
            elif hasattr(db, '__len__'):
                print(f"📊 В базе {len(db)} новостей.")
            else:
                print("📊 Не удалось получить количество новостей.")
            continue

        # --- 4) Очистка базы ---
        elif choice == "4":
            confirm = await safe_input("Вы уверены, что хотите очистить базу? (yes/no): ")
            if confirm.lower() in ['yes', 'y', 'да', 'д']:
                if hasattr(db, 'clear_all'):
                    db.clear_all()
                elif hasattr(db, 'news_db'):
                    db.news_db.clear()
                    db.sent_ids.clear()
                    db.save_db()
                    db.save_sent_ids()
                print("🗑️ NEWS_DB и sent_ids.json очищены.")
            else:
                print("❌ Очистка отменена.")
            continue

        # --- 5) Очистка поврежденных записей ---
        elif choice == "5":
            broken_count = 0
            if hasattr(db, 'news_db'):
                for news_id, data in list(db.news_db.items()):
                    if data.get("message_id") is None:
                        if hasattr(db, 'delete_news'):
                            db.delete_news(news_id)
                        else:
                            del db.news_db[news_id]
                        broken_count += 1
                if hasattr(db, 'save_db'):
                    db.save_db()
            print(f"🔧 Удалено {broken_count} записей с поврежденными message_id.")
            continue

        # --- 0) Выход ---
        elif choice == "0":
            print("👋 Выход из режима загрузки новостей.")
            break
        else:
            print("❌ Неверный выбор. Попробуйте снова.")
            continue

        # --- Отправка новостей в модерацию ---
        if 'news_list' in locals():
            count = 0
            failed_count = 0

            for i, item in enumerate(news_list):
                if not all(k in item for k in ["title", "source", "date", "url", "preview", "full_text"]):
                    print(f"⚠️ Пропущена новость #{i} — не хватает ключей")
                    failed_count += 1
                    continue

                try:
                    item_id = make_news_id(item, i)

                    # Check if already sent (handle both database types)
                    already_sent = False
                    if hasattr(db, 'is_sent'):
                        already_sent = db.is_sent(item_id)
                    elif hasattr(db, 'sent_ids') and item_id in db.sent_ids:
                        already_sent = True

                    if already_sent:
                        print(f"⏩ Новость {item_id} уже была отправлена ранее, пропускаем")
                        continue

                    item["id"] = item_id
                    print(f"📨 Отправляем новость {item_id} в канал модерации...")
                    await send_to_moderation(bot, item, db)
                    count += 1

                    # Небольшая задержка между отправками
                    await asyncio.sleep(1)

                except Exception as e:
                    print(f"❗ Ошибка отправки новости #{i}: {e}")
                    failed_count += 1

            print(f"✅ Всего отправлено в модерацию: {count} новых новостей.")
            if failed_count > 0:
                print(f"⚠️ Не удалось обработать: {failed_count} новостей.")

            # Очищаем переменную для следующей итерации
            del news_list
===== C:\Users\SK-GROUP\PycharmProjects\PythonProject\energy_news_project\bot\database.py =====
# bot/database.py
import json
import os
import shutil
import threading
import time
from contextlib import contextmanager
from datetime import datetime, timedelta
from typing import Dict, Set, Optional, Any
import logging

logger = logging.getLogger(__name__)


class SafeNewsDB:
    """Thread-safe news database with transactions, caching, and automatic backups."""

    def __init__(self, db_file="data/news_db.json", sent_ids_file="data/sent_ids.json", backup_interval=3600):
        self.db_file = db_file
        self.sent_ids_file = sent_ids_file
        self.backup_interval = backup_interval

        # Ensure directories exist
        os.makedirs(os.path.dirname(self.db_file), exist_ok=True)
        os.makedirs(os.path.dirname(self.sent_ids_file), exist_ok=True)

        # Thread safety
        self._lock = threading.RLock()

        # In-memory data
        self.news_db: Dict[str, Any] = {}
        self.sent_ids: Set[str] = set()

        # Load existing data
        self._load_db()
        self._load_sent_ids()

        # Background backup
        self._last_backup = time.time()
        self._start_backup_thread()

        logger.info(f"Database initialized: {len(self.news_db)} news items, {len(self.sent_ids)} sent IDs")

    def _start_backup_thread(self):
        """Start background thread for periodic backups."""

        def backup_worker():
            while True:
                try:
                    time.sleep(300)  # Check every 5 minutes
                    if time.time() - self._last_backup > self.backup_interval:
                        self._create_backup()
                        self._last_backup = time.time()
                except Exception as e:
                    logger.error(f"Backup thread error: {e}")

        backup_thread = threading.Thread(target=backup_worker, daemon=True)
        backup_thread.start()

    def _create_backup(self):
        """Create backup files with timestamp."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        try:
            with self._lock:
                # Backup news database
                backup_db_file = f"{self.db_file}.backup_{timestamp}"
                if os.path.exists(self.db_file):
                    shutil.copy2(self.db_file, backup_db_file)

                # Backup sent IDs
                backup_ids_file = f"{self.sent_ids_file}.backup_{timestamp}"
                if os.path.exists(self.sent_ids_file):
                    shutil.copy2(self.sent_ids_file, backup_ids_file)

                logger.info(f"Backup created: {backup_db_file}")

                # Clean old backups (keep only last 10)
                self._cleanup_old_backups()

        except Exception as e:
            logger.error(f"Backup creation failed: {e}")

    def _cleanup_old_backups(self):
        """Remove old backup files, keeping only the 10 most recent."""
        try:
            db_dir = os.path.dirname(self.db_file)
            db_name = os.path.basename(self.db_file)
            ids_name = os.path.basename(self.sent_ids_file)

            # Get all backup files
            db_backups = [f for f in os.listdir(db_dir) if f.startswith(f"{db_name}.backup_")]
            ids_backups = [f for f in os.listdir(db_dir) if f.startswith(f"{ids_name}.backup_")]

            # Sort by modification time and remove old ones
            for backups in [db_backups, ids_backups]:
                if len(backups) > 10:
                    backups.sort(key=lambda x: os.path.getmtime(os.path.join(db_dir, x)))
                    for old_backup in backups[:-10]:
                        os.remove(os.path.join(db_dir, old_backup))
                        logger.debug(f"Removed old backup: {old_backup}")

        except Exception as e:
            logger.error(f"Backup cleanup failed: {e}")

    def _load_db(self):
        """Load news database from file."""
        if os.path.exists(self.db_file):
            try:
                with open(self.db_file, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    if isinstance(data, dict):
                        self.news_db = data
                    else:
                        logger.warning("Invalid database format, starting with empty database")
                        self.news_db = {}
            except (json.JSONDecodeError, IOError) as e:
                logger.error(f"Failed to load database: {e}")
                # Try to load from latest backup
                self._restore_from_backup()

    def _load_sent_ids(self):
        """Load sent IDs from file."""
        if os.path.exists(self.sent_ids_file):
            try:
                with open(self.sent_ids_file, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    if isinstance(data, list):
                        self.sent_ids = set(data)
                    else:
                        logger.warning("Invalid sent IDs format, starting with empty set")
                        self.sent_ids = set()
            except (json.JSONDecodeError, IOError) as e:
                logger.error(f"Failed to load sent IDs: {e}")
                self.sent_ids = set()

    def _restore_from_backup(self):
        """Restore from the most recent backup."""
        try:
            db_dir = os.path.dirname(self.db_file)
            db_name = os.path.basename(self.db_file)

            backups = [f for f in os.listdir(db_dir) if f.startswith(f"{db_name}.backup_")]
            if not backups:
                logger.warning("No backups found")
                return

            # Get most recent backup
            latest_backup = max(backups, key=lambda x: os.path.getmtime(os.path.join(db_dir, x)))
            backup_path = os.path.join(db_dir, latest_backup)

            with open(backup_path, "r", encoding="utf-8") as f:
                self.news_db = json.load(f)

            logger.info(f"Restored from backup: {latest_backup}")

        except Exception as e:
            logger.error(f"Failed to restore from backup: {e}")
            self.news_db = {}

    def _save_db(self):
        """Save news database to file."""
        try:
            # Write to temporary file first
            temp_file = f"{self.db_file}.tmp"
            with open(temp_file, "w", encoding="utf-8") as f:
                json.dump(self.news_db, f, ensure_ascii=False, indent=2)

            # Atomic move
            shutil.move(temp_file, self.db_file)

        except Exception as e:
            logger.error(f"Failed to save database: {e}")
            # Clean up temp file if it exists
            if os.path.exists(f"{self.db_file}.tmp"):
                os.remove(f"{self.db_file}.tmp")
            raise

    def _save_sent_ids(self):
        """Save sent IDs to file."""
        try:
            temp_file = f"{self.sent_ids_file}.tmp"
            with open(temp_file, "w", encoding="utf-8") as f:
                json.dump(list(self.sent_ids), f, ensure_ascii=False, indent=2)

            shutil.move(temp_file, self.sent_ids_file)

        except Exception as e:
            logger.error(f"Failed to save sent IDs: {e}")
            if os.path.exists(f"{self.sent_ids_file}.tmp"):
                os.remove(f"{self.sent_ids_file}.tmp")
            raise

    @contextmanager
    def transaction(self):
        """Context manager for database transactions."""
        with self._lock:
            old_news_db = self.news_db.copy()
            old_sent_ids = self.sent_ids.copy()

            try:
                yield
                self._save_db()
                self._save_sent_ids()
            except Exception as e:
                # Rollback on error
                self.news_db = old_news_db
                self.sent_ids = old_sent_ids
                logger.error(f"Transaction rolled back due to error: {e}")
                raise

    def add_news(self, news_id: str, news_data: dict, message_id: int, channel_id: str):
        """Add news item to database."""
        with self.transaction():
            self.news_db[news_id] = {
                "news_data": news_data,
                "message_id": message_id,
                "channel_id": channel_id,
                "created_at": datetime.now().isoformat(),
                "updated_at": datetime.now().isoformat()
            }
            self.sent_ids.add(news_id)
            logger.debug(f"Added news: {news_id}")

    def get_news(self, news_id: str) -> Optional[dict]:
        """Get news item by ID."""
        with self._lock:
            return self.news_db.get(news_id)

    def update_news(self, news_id: str, updates: dict):
        """Update news item."""
        with self.transaction():
            if news_id in self.news_db:
                self.news_db[news_id].update(updates)
                self.news_db[news_id]["updated_at"] = datetime.now().isoformat()
                logger.debug(f"Updated news: {news_id}")
                return True
            return False

    def delete_news(self, news_id: str):
        """Delete news item."""
        with self.transaction():
            if news_id in self.news_db:
                del self.news_db[news_id]
                self.sent_ids.discard(news_id)
                logger.debug(f"Deleted news: {news_id}")
                return True
            return False

    def is_sent(self, news_id: str) -> bool:
        """Check if news was already sent."""
        with self._lock:
            return news_id in self.sent_ids

    def get_all_news_ids(self) -> Set[str]:
        """Get all news IDs."""
        with self._lock:
            return set(self.news_db.keys())

    def get_stats(self) -> dict:
        """Get database statistics."""
        with self._lock:
            total_news = len(self.news_db)
            sent_count = len(self.sent_ids)

            # Count by status
            pending = 0
            published = 0
            rejected = 0

            for news_data in self.news_db.values():
                status = news_data.get("status", "pending")
                if status == "pending":
                    pending += 1
                elif status == "published":
                    published += 1
                elif status == "rejected":
                    rejected += 1

            return {
                "total_news": total_news,
                "sent_count": sent_count,
                "pending": pending,
                "published": published,
                "rejected": rejected,
                "db_size_mb": os.path.getsize(self.db_file) / 1024 / 1024 if os.path.exists(self.db_file) else 0
            }

    def cleanup_old_news(self, days: int = 30):
        """Remove news older than specified days."""
        cutoff_date = datetime.now() - timedelta(days=days)
        cutoff_str = cutoff_date.isoformat()

        with self.transaction():
            to_remove = []
            for news_id, news_data in self.news_db.items():
                created_at = news_data.get("created_at", "")
                if created_at and created_at < cutoff_str:
                    to_remove.append(news_id)

            removed_count = 0
            for news_id in to_remove:
                if self.delete_news(news_id):
                    removed_count += 1

            logger.info(f"Cleaned up {removed_count} old news items")
            return removed_count

    def clear_all(self):
        """Clear all data (use with caution)."""
        with self.transaction():
            self.news_db.clear()
            self.sent_ids.clear()
            logger.warning("Database cleared")

    def force_save(self):
        """Force save all data to disk."""
        with self._lock:
            self._save_db()
            self._save_sent_ids()
            logger.info("Database force saved")

    def __len__(self):
        """Return number of news items."""
        with self._lock:
            return len(self.news_db)

    def __contains__(self, news_id):
        """Check if news ID exists."""
        with self._lock:
            return news_id in self.news_db

    # Compatibility methods for legacy code
    def save_db(self):
        """Legacy compatibility method - maps to force_save()."""
        self.force_save()

    def save_sent_ids(self):
        """Legacy compatibility method - maps to force_save()."""
        self.force_save()
===== C:\Users\SK-GROUP\PycharmProjects\PythonProject\energy_news_project\bot\formatters.py =====
# bot/formatters.py
import re
import html

def safe_clean_text(text: str) -> str:
    """
    Очищает текст от HTML-тегов, лишних пробелов и спецсимволов.
    """
    if not text:
        return ""
    # Удаляем HTML теги
    text = re.sub(r"<[^>]+>", "", text)
    # Раскодируем HTML сущности
    text = html.unescape(text)
    # Заменяем множественные пробелы на один
    text = re.sub(r"\s+", " ", text).strip()
    return text


def format_news_for_publication(news_item: dict, max_length: int = 3800) -> str:
    """
    Форматирует новость для публикации в канал Telegram.
    """
    title = safe_clean_text(news_item.get("title", "Без заголовка"))
    text = safe_clean_text(news_item.get("full_text", ""))
    source = safe_clean_text(news_item.get("source", "Источник не указан"))
    url = news_item.get("url", "")

    if len(text) > max_length:
        text = text[:max_length] + "... [обрезано]"

    return f"🔥 {title}\n\n{text}\n\nИсточник: {source}\nОригинал: {url}"
===== C:\Users\SK-GROUP\PycharmProjects\PythonProject\energy_news_project\bot\telegram_bot.py =====
import asyncio
import hashlib
import logging
from telegram import Bot, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.error import TelegramError, RetryAfter
from bot.formatters import format_news_for_publication
from bot.database import SafeNewsDB

logger = logging.getLogger(__name__)

# --- Константы каналов ---
MODERATION_CHANNEL = "-1002996332660"
PUBLISH_CHANNEL = "-1003006895565"


# --- Утилиты ---
def make_news_id(item, index=0):
    """
    Генерирует уникальный ID новости на основе URL, заголовка или превью.
    """
    key = (item.get("url") or "").strip()
    if not key:
        key = f"{item.get('title', '')}-{item.get('date', '')}".strip()
    if not key:
        key = item.get("preview", "")[:120]
    return hashlib.sha256(key.encode("utf-8")).hexdigest()[:16]


async def send_with_delay(bot: Bot, chat_id: str, text: str, reply_markup=None,
                          pause: float = 1.5, max_retries: int = 5):
    """
    Отправка сообщения с задержкой и повторной попыткой при ошибках.
    """
    attempt = 0
    while attempt < max_retries:
        try:
            message = await bot.send_message(
                chat_id=chat_id,
                text=text,
                reply_markup=reply_markup,
                disable_web_page_preview=True
                # Убираем parse_mode='HTML' чтобы избежать ошибок парсинга
            )
            await asyncio.sleep(pause)
            return message
        except RetryAfter as e:
            wait_time = e.retry_after
            logger.warning(f"Flood control: ждём {wait_time} сек...")
            await asyncio.sleep(wait_time)
            attempt += 1
        except TelegramError as e:
            logger.error(f"Ошибка Telegram при отправке: {e}")
            return None
        except Exception as e:
            logger.error(f"Неизвестная ошибка при отправке: {e}")
            return None
    logger.error("Не удалось отправить сообщение после всех попыток.")
    return None


async def send_to_moderation(bot: Bot, news_item: dict, db: SafeNewsDB):
    """
    Отправка новости в канал модерации с кнопками approve/reject/edit.
    """
    news_id = news_item["id"]

    # Безопасная очистка текста от HTML и экранирование
    def clean_and_safe_text(text):
        if not text:
            return ""
        # Удаляем HTML теги
        import re
        text = re.sub(r'<[^>]+>', '', str(text))
        # Убираем лишние пробелы
        text = re.sub(r'\s+', ' ', text).strip()
        return text

    title = clean_and_safe_text(news_item.get('title', 'Без заголовка'))
    preview = clean_and_safe_text(news_item.get('preview', ''))
    source = clean_and_safe_text(news_item.get('source', 'Источник не указан'))
    date = clean_and_safe_text(news_item.get('date', ''))
    url = news_item.get('url', '')

    text = (
        f"📰 {title}\n\n"
        f"{preview}\n\n"
        f"Источник: {source} ({date})\n"
        f"{url}"
    )

    keyboard = [
        [
            InlineKeyboardButton("✅ Опубликовать", callback_data=f"approve|{news_id}"),
            InlineKeyboardButton("❌ Отклонить", callback_data=f"reject|{news_id}"),
            InlineKeyboardButton("✏️ Редактировать", callback_data=f"edit|{news_id}")
        ]
    ]

    logger.info(f"Отправка новости {news_id} в канал модерации...")
    message = await send_with_delay(
        bot,
        MODERATION_CHANNEL,
        text,
        reply_markup=InlineKeyboardMarkup(keyboard)
    )

    if message and message.message_id:
        # ИСПРАВЛЕНО: Проверяем, что message_id действительно получен
        db.add_news(news_id, news_item, message.message_id, MODERATION_CHANNEL)
        logger.info(f"Новость {news_id} отправлена в модерацию (message_id={message.message_id})")

        # Дополнительная проверка, что данные сохранились корректно
        saved_data = db.get_news(news_id)
        if saved_data and saved_data.get("message_id"):
            logger.info(f"Подтверждение: message_id {saved_data['message_id']} сохранен для новости {news_id}")
        else:
            logger.error(f"КРИТИЧЕСКАЯ ОШИБКА: message_id не сохранился для новости {news_id}")
    else:
        logger.error(f"Не удалось отправить новость {news_id} в канал модерации или получить message_id.")
===== C:\Users\SK-GROUP\PycharmProjects\PythonProject\energy_news_project\bot\telegram_handlers.py =====
import asyncio
import logging
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import ContextTypes
from telegram.error import TelegramError
from bot.telegram_bot import PUBLISH_CHANNEL
from bot.formatters import format_news_for_publication, safe_clean_text
from bot.database import SafeNewsDB

logger = logging.getLogger(__name__)


async def split_and_send_text(bot, chat_id, text, max_length=4000):
    """
    Разбивает длинный текст на части и отправляет несколько сообщений.
    Возвращает список ID отправленных сообщений.
    """
    message_ids = []

    if len(text) <= max_length:
        try:
            message = await bot.send_message(chat_id=chat_id, text=text)
            if message:
                message_ids.append(message.message_id)
            await asyncio.sleep(0.5)  # Небольшая задержка
        except Exception as e:
            logger.error(f"Ошибка отправки сообщения: {e}")
        return message_ids

    # Разбиваем по предложениям для лучшей читаемости
    sentences = text.split('. ')
    current_chunk = ""

    for sentence in sentences:
        if len(current_chunk + sentence + '. ') <= max_length:
            current_chunk += sentence + '. '
        else:
            if current_chunk:
                try:
                    message = await bot.send_message(chat_id=chat_id, text=current_chunk.strip())
                    if message:
                        message_ids.append(message.message_id)
                    await asyncio.sleep(0.5)  # Задержка между сообщениями
                except Exception as e:
                    logger.error(f"Ошибка отправки части сообщения: {e}")
                current_chunk = sentence + '. '
            else:
                # Если предложение слишком длинное, разбиваем принудительно
                while len(sentence) > max_length:
                    try:
                        message = await bot.send_message(chat_id=chat_id, text=sentence[:max_length])
                        if message:
                            message_ids.append(message.message_id)
                        await asyncio.sleep(0.5)
                    except Exception as e:
                        logger.error(f"Ошибка отправки длинного сообщения: {e}")
                    sentence = sentence[max_length:]
                current_chunk = sentence + '. ' if sentence else ""

    # Отправляем остаток
    if current_chunk:
        try:
            message = await bot.send_message(chat_id=chat_id, text=current_chunk.strip())
            if message:
                message_ids.append(message.message_id)
            await asyncio.sleep(0.5)
        except Exception as e:
            logger.error(f"Ошибка отправки остатка сообщения: {e}")

    return message_ids


async def safe_delete_messages(bot, chat_id, message_ids, news_id):
    """
    Безопасное удаление множественных сообщений с обработкой ошибок.
    """
    if not message_ids:
        logger.warning(f"Нет сообщений для удаления для новости {news_id}")
        return 0

    deleted_count = 0
    for message_id in message_ids:
        if message_id is None:
            continue
        try:
            await bot.delete_message(chat_id=chat_id, message_id=message_id)
            deleted_count += 1
            logger.info(f"Сообщение {message_id} для новости {news_id} удалено")
            await asyncio.sleep(0.1)  # Небольшая задержка между удалениями
        except TelegramError as e:
            logger.warning(f"Не удалось удалить сообщение {message_id} для новости {news_id}: {e}")
        except Exception as e:
            logger.error(f"Неожиданная ошибка при удалении сообщения {message_id}: {e}")

    logger.info(f"Удалено {deleted_count} из {len(message_ids)} сообщений для новости {news_id}")
    return deleted_count


# --- Обработчик нажатий кнопок ---
async def button_handler(update: Update, context: ContextTypes.DEFAULT_TYPE, db: SafeNewsDB):
    query = update.callback_query
    await query.answer()

    try:
        action, news_id = query.data.split("|", 1)
        logger.info(f"Обрабатываем действие: {action} для новости {news_id}")

        data_entry = db.get_news(news_id)
        if not data_entry:
            await query.edit_message_text("⚠️ Запись не найдена.")
            return

        channel_id = data_entry["channel_id"]
        message_id = data_entry["message_id"]
        news_item = data_entry["news_data"]

        if action == "approve":
            # Получаем свежие данные новости из базы
            data_entry = db.get_news(news_id)
            if not data_entry:
                await query.edit_message_text("⚠️ Запись не найдена.")
                return

            news_item = data_entry["news_data"]
            publication_text = format_news_for_publication(news_item)

            # Проверяем, была ли новость отредактирована
            edit_status = " (ОТРЕДАКТИРОВАНО)" if news_item.get("edited", False) else ""

            # Публикуем в канал
            logger.info(f"Начинаем публикацию в канал {PUBLISH_CHANNEL}")
            try:
                await context.bot.send_message(
                    chat_id=PUBLISH_CHANNEL,
                    text=publication_text,
                    disable_web_page_preview=True,
                )
                logger.info(f"Успешно опубликовано в канал")

                # Отправляем уведомление о публикации в личку модератору (если возможно)
                try:
                    await query.message.reply_text(f"✅ Новость {news_id} успешно опубликована{edit_status.lower()}!")
                except Exception as notify_error:
                    logger.warning(f"Не удалось отправить уведомление модератору: {notify_error}")

                # Удаляем основное сообщение из канала модерации
                message_ids_to_delete = [message_id]

                # Добавляем ID сообщений с полным текстом, если они есть
                if news_item.get("preview_message_ids") and news_item.get("preview_chat_id"):
                    # Сначала удаляем сообщения превью из личного чата
                    await safe_delete_messages(
                        context.bot,
                        news_item["preview_chat_id"],
                        news_item["preview_message_ids"],
                        news_id
                    )
                    logger.info(
                        f"Удалены сообщения превью из личного чата {news_item['preview_chat_id']}: {news_item['preview_message_ids']}")

                # Удаляем основное сообщение из канала модерации
                await safe_delete_messages(context.bot, channel_id, [message_id], news_id)

                # Удаляем запись из базы данных
                db.delete_news(news_id)
                logger.info(f"Новость {news_id} опубликована{edit_status.lower()} и удалена из модерации.")

            except Exception as publish_error:
                logger.error(f"Ошибка публикации новости {news_id}: {publish_error}")
                try:
                    await query.edit_message_text(f"❌ Ошибка публикации: {publish_error}")
                except Exception:
                    await query.message.reply_text(f"❌ Ошибка публикации: {publish_error}")

        elif action == "reject":
            # Получаем свежие данные новости из базы
            data_entry = db.get_news(news_id)
            if not data_entry:
                await query.edit_message_text("⚠️ Запись не найдена.")
                return

            news_item = data_entry["news_data"]

            # Отправляем уведомление о отклонении (если возможно)
            try:
                await query.message.reply_text(f"❌ Новость {news_id} отклонена и удалена.")
            except Exception as notify_error:
                logger.warning(f"Не удалось отправить уведомление об отклонении: {notify_error}")

            # Удаляем основное сообщение и все связанные сообщения
            if news_item.get("preview_message_ids") and news_item.get("preview_chat_id"):
                # Сначала удаляем сообщения превью из личного чата
                await safe_delete_messages(
                    context.bot,
                    news_item["preview_chat_id"],
                    news_item["preview_message_ids"],
                    news_id
                )
                logger.info(
                    f"Удалены сообщения превью из личного чата {news_item['preview_chat_id']}: {news_item['preview_message_ids']}")

            # Удаляем основное сообщение из канала модерации
            await safe_delete_messages(context.bot, channel_id, [message_id], news_id)

            # Удаляем запись из базы данных
            db.delete_news(news_id)
            logger.info(f"Новость {news_id} отклонена и удалена из модерации.")

        elif action == "edit":
            # Показываем полный текст статьи в нескольких сообщениях
            full_text = news_item.get("full_text", "")
            if full_text:
                # Отправляем заголовок
                header_message = await query.message.reply_text(
                    f"📝 Текущий полный текст новости (ID: {news_id}):"
                )

                # Отправляем текст частями и сохраняем ID всех сообщений
                text_message_ids = await split_and_send_text(context.bot, query.message.chat_id, full_text)

                # Сохраняем ID всех сообщений с превью И chat_id в базе данных
                all_preview_ids = [header_message.message_id] + text_message_ids
                db.news_db[news_id]["news_data"]["preview_message_ids"] = all_preview_ids
                db.news_db[news_id]["news_data"]["preview_chat_id"] = query.message.chat_id
                db.save_db()

                logger.info(
                    f"Сохранены ID сообщений с превью для новости {news_id}: {all_preview_ids} в чате {query.message.chat_id}")
            else:
                preview_message = await query.message.reply_text("⚠️ Полный текст новости отсутствует.")
                # Сохраняем ID этого сообщения тоже
                db.news_db[news_id]["news_data"]["preview_message_ids"] = [preview_message.message_id]
                db.news_db[news_id]["news_data"]["preview_chat_id"] = query.message.chat_id
                db.save_db()

            await query.message.reply_text(
                "✏️ Отправьте исправленный текст новости.\n"
                "Чтобы оставить как есть — отправьте /skip\n"
                "⚠️ После редактирования сообщение в канале модерации будет обновлено."
            )
            context.user_data["editing_news_id"] = news_id

    except Exception as e:
        logger.error(f"Ошибка обработки callback: {e}")
        try:
            await query.edit_message_text(f"⚠️ Ошибка: {e}")
        except Exception:
            # Если не можем отредактировать, отправляем новое сообщение
            await query.message.reply_text(f"⚠️ Ошибка: {e}")


# --- Обработчик редактирования текста ---
async def edit_text_handler(update: Update, context: ContextTypes.DEFAULT_TYPE, db: SafeNewsDB):
    logger.info(f"edit_text_handler вызван с текстом: {update.message.text[:100]}")
    logger.info(f"user_data: {context.user_data}")

    # Проверяем, что user_data не None
    if context.user_data is None:
        logger.warning("User data is None, skipping edit handling")
        return

    news_id = context.user_data.get("editing_news_id")
    logger.info(f"editing_news_id: {news_id}")

    if not news_id:
        logger.info("Нет активного редактирования, пропускаем")
        return

    if update.message.text == "/skip":
        await update.message.reply_text("✅ Редактирование пропущено.")
        context.user_data["editing_news_id"] = None
        return

    # Получаем данные новости
    data_entry = db.get_news(news_id)
    if not data_entry:
        await update.message.reply_text("⚠️ Новость не найдена в базе.")
        context.user_data["editing_news_id"] = None
        return

    # Обновляем текст новости
    db.news_db[news_id]["news_data"]["full_text"] = update.message.text
    # Помечаем, что новость была отредактирована
    db.news_db[news_id]["news_data"]["edited"] = True

    # Удаляем старые сообщения с превью, если они есть
    # ВАЖНО: превью отправляются в личный чат, получаем правильный chat_id
    if data_entry["news_data"].get("preview_message_ids") and data_entry["news_data"].get("preview_chat_id"):
        await safe_delete_messages(
            context.bot,
            data_entry["news_data"]["preview_chat_id"],  # Используем сохраненный chat_id
            data_entry["news_data"]["preview_message_ids"],
            news_id
        )
        # Очищаем список ID сообщений с превью и chat_id
        db.news_db[news_id]["news_data"]["preview_message_ids"] = []
        db.news_db[news_id]["news_data"]["preview_chat_id"] = None

    db.save_db()

    # Отладочная информация
    logger.info(f"Текст новости {news_id} обновлен на: {update.message.text[:100]}")

    # Обновляем сообщение в канале модерации
    try:
        channel_id = data_entry["channel_id"]
        message_id = data_entry["message_id"]
        news_item = data_entry["news_data"]

        # Проверяем, что message_id существует
        if message_id is None:
            logger.warning(f"Нельзя обновить сообщение для новости {news_id}: message_id is None")
            await update.message.reply_text(
                "✅ Текст новости обновлён!\n"
                "⚠️ Сообщение в канале модерации не найдено, но изменения сохранены.\n"
                "Нажмите кнопку 'Опубликовать' для публикации отредактированной версии."
            )
            context.user_data["editing_news_id"] = None
            return

        # Функция для безопасного экранирования HTML
        def safe_escape_html(text):
            if not text:
                return ""
            # Сначала удаляем все HTML-теги
            import re
            text = re.sub(r'<[^>]+>', '', str(text))
            # Затем экранируем специальные символы
            return text.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')

        # Безопасно обрабатываем текст для отображения
        clean_title = safe_escape_html(news_item.get("title", ""))
        clean_preview = safe_escape_html(news_item.get("preview", ""))
        clean_source = safe_escape_html(news_item.get("source", ""))
        clean_date = safe_escape_html(news_item.get("date", ""))
        clean_url = news_item.get('url', '')

        # Создаем новую кнопочную панель
        keyboard = [
            [
                InlineKeyboardButton("✅ Опубликовать", callback_data=f"approve|{news_id}"),
                InlineKeyboardButton("❌ Отклонить", callback_data=f"reject|{news_id}"),
                InlineKeyboardButton("✏️ Редактировать", callback_data=f"edit|{news_id}")
            ]
        ]

        # Формируем текст без HTML-парсинга для избежания ошибок
        updated_text = (
            f"📰 {clean_title} ✏️ ОТРЕДАКТИРОВАНО\n\n"
            f"{clean_preview}\n\n"
            f"Источник: {clean_source} ({clean_date})\n"
            f"{clean_url}"
        )

        await context.bot.edit_message_text(
            chat_id=channel_id,
            message_id=message_id,
            text=updated_text,
            reply_markup=InlineKeyboardMarkup(keyboard),
            disable_web_page_preview=True
            # Убираем parse_mode='HTML' чтобы избежать ошибок парсинга
        )

        await update.message.reply_text(
            "✅ Текст новости обновлён и сообщение в канале модерации обновлено!\n"
            "Теперь нажмите кнопку 'Опубликовать' для публикации отредактированной версии."
        )

    except Exception as update_error:
        logger.error(f"Ошибка обновления сообщения в канале модерации: {update_error}")
        await update.message.reply_text(
            "✅ Текст новости обновлён!\n"
            "⚠️ Не удалось обновить сообщение в канале модерации, но изменения сохранены.\n"
            "Нажмите кнопку 'Опубликовать' для публикации отредактированной версии."
        )

    context.user_data["editing_news_id"] = None


# --- Обработчик команды /skip ---
async def skip_edit_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    # Проверяем, что user_data не None
    if context.user_data is None:
        logger.warning("User data is None, skipping skip command")
        return

    news_id = context.user_data.get("editing_news_id")
    if news_id:
        context.user_data["editing_news_id"] = None
        await update.message.reply_text("✅ Редактирование пропущено.")
    else:
        await update.message.reply_text("ℹ️ Нет активного процесса редактирования.")
===== C:\Users\SK-GROUP\PycharmProjects\PythonProject\energy_news_project\bot\telegram_handlers_patched.py =====
# bot/telegram_handlers_patched.py
import asyncio
import logging
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import ContextTypes
from telegram.error import TelegramError
from bot.telegram_bot import PUBLISH_CHANNEL
from bot.formatters import format_news_for_publication, safe_clean_text

logger = logging.getLogger(__name__)

# Store editing sessions globally (temporary fix for context issues)
EDITING_SESSIONS = {}


async def split_and_send_text(bot, chat_id, text, max_length=4000):
    """
    Разбивает длинный текст на части и отправляет несколько сообщений.
    Возвращает список ID отправленных сообщений.
    """
    message_ids = []

    if len(text) <= max_length:
        try:
            message = await bot.send_message(chat_id=chat_id, text=text)
            if message:
                message_ids.append(message.message_id)
            await asyncio.sleep(0.5)  # Небольшая задержка
        except Exception as e:
            logger.error(f"Ошибка отправки сообщения: {e}")
        return message_ids

    # Разбиваем по предложениям для лучшей читаемости
    sentences = text.split('. ')
    current_chunk = ""

    for sentence in sentences:
        if len(current_chunk + sentence + '. ') <= max_length:
            current_chunk += sentence + '. '
        else:
            if current_chunk:
                try:
                    message = await bot.send_message(chat_id=chat_id, text=current_chunk.strip())
                    if message:
                        message_ids.append(message.message_id)
                    await asyncio.sleep(0.5)  # Задержка между сообщениями
                except Exception as e:
                    logger.error(f"Ошибка отправки части сообщения: {e}")
                current_chunk = sentence + '. '
            else:
                # Если предложение слишком длинное, разбиваем принудительно
                while len(sentence) > max_length:
                    try:
                        message = await bot.send_message(chat_id=chat_id, text=sentence[:max_length])
                        if message:
                            message_ids.append(message.message_id)
                        await asyncio.sleep(0.5)
                    except Exception as e:
                        logger.error(f"Ошибка отправки длинного сообщения: {e}")
                    sentence = sentence[max_length:]
                current_chunk = sentence + '. ' if sentence else ""

    # Отправляем остаток
    if current_chunk:
        try:
            message = await bot.send_message(chat_id=chat_id, text=current_chunk.strip())
            if message:
                message_ids.append(message.message_id)
            await asyncio.sleep(0.5)
        except Exception as e:
            logger.error(f"Ошибка отправки остатка сообщения: {e}")

    return message_ids


async def safe_delete_messages(bot, chat_id, message_ids, news_id):
    """
    Безопасное удаление множественных сообщений с обработкой ошибок.
    """
    if not message_ids:
        logger.warning(f"Нет сообщений для удаления для новости {news_id}")
        return 0

    deleted_count = 0
    for message_id in message_ids:
        if message_id is None:
            continue
        try:
            await bot.delete_message(chat_id=chat_id, message_id=message_id)
            deleted_count += 1
            logger.info(f"Сообщение {message_id} для новости {news_id} удалено")
            await asyncio.sleep(0.1)  # Небольшая задержка между удалениями
        except TelegramError as e:
            logger.warning(f"Не удалось удалить сообщение {message_id} для новости {news_id}: {e}")
        except Exception as e:
            logger.error(f"Неожиданная ошибка при удалении сообщения {message_id}: {e}")

    logger.info(f"Удалено {deleted_count} из {len(message_ids)} сообщений для новости {news_id}")
    return deleted_count


# --- Обработчик нажатий кнопок ---
async def button_handler(update: Update, context: ContextTypes.DEFAULT_TYPE, db):
    query = update.callback_query
    await query.answer()

    try:
        action, news_id = query.data.split("|", 1)
        logger.info(f"Обрабатываем действие: {action} для новости {news_id}")

        data_entry = db.get_news(news_id)
        if not data_entry:
            await query.edit_message_text("⚠️ Запись не найдена.")
            return

        channel_id = data_entry["channel_id"]
        message_id = data_entry["message_id"]
        fresh_data_entry = db.get_news(news_id)
        fresh_data_entry = db.get_news(news_id)
        news_item = fresh_data_entry["news_data"]

        # Fix for bot/telegram_handlers_patched.py - Replace the approve section with this:

        if action == "approve":
            # CRITICAL: Always get fresh data from database before publication
            fresh_data_entry = db.get_news(news_id)
            if not fresh_data_entry:
                await query.edit_message_text("⚠️ Запись не найдена.")
                return

            # Use fresh data for publication
            news_item = fresh_data_entry["news_data"]

            # Double-check: Log the text being published for debugging
            logger.info(f"Publishing news {news_id} with full_text: {news_item.get('full_text', '')[:100]}...")

            publication_text = format_news_for_publication(news_item)

            # Check if news was edited
            edit_status = " (ОТРЕДАКТИРОВАНО)" if news_item.get("edited", False) else ""

            # Publish to channel
            logger.info(f"Начинаем публикацию в канал {PUBLISH_CHANNEL}")
            try:
                await context.bot.send_message(
                    chat_id=PUBLISH_CHANNEL,
                    text=publication_text,
                    disable_web_page_preview=True,
                )
                logger.info(f"Успешно опубликовано в канал")

                # Send confirmation
                try:
                    await query.message.reply_text(f"✅ Новость {news_id} успешно опубликована{edit_status.lower()}!")
                except Exception as notify_error:
                    logger.warning(f"Не удалось отправить уведомление модератору: {notify_error}")

                # Get the updated data again for cleanup (in case anything changed)
                cleanup_data_entry = db.get_news(news_id)
                if cleanup_data_entry:
                    channel_id = cleanup_data_entry["channel_id"]
                    message_id = cleanup_data_entry["message_id"]
                    news_item = cleanup_data_entry["news_data"]

                    # Clean up preview messages if they exist
                    if news_item.get("preview_message_ids") and news_item.get("preview_chat_id"):
                        await safe_delete_messages(
                            context.bot,
                            news_item["preview_chat_id"],
                            news_item["preview_message_ids"],
                            news_id
                        )
                        logger.info(
                            f"Удалены сообщения превью из личного чата {news_item['preview_chat_id']}: {news_item['preview_message_ids']}")

                    # Delete moderation message
                    await safe_delete_messages(context.bot, channel_id, [message_id], news_id)

                    # Remove from database
                    db.delete_news(news_id)
                    logger.info(f"Новость {news_id} опубликована{edit_status.lower()} и удалена из модерации.")

            except Exception as publish_error:
                logger.error(f"Ошибка публикации новости {news_id}: {publish_error}")
                try:
                    await query.edit_message_text(f"❌ Ошибка публикации: {publish_error}")
                except Exception:
                    await query.message.reply_text(f"❌ Ошибка публикации: {publish_error}")

        elif action == "reject":
            # Получаем свежие данные новости из базы
            data_entry = db.get_news(news_id)
            if not data_entry:
                await query.edit_message_text("⚠️ Запись не найдена.")
                return

            fresh_data_entry = db.get_news(news_id)
            news_item = fresh_data_entry["news_data"]

            # Отправляем уведомление о отклонении (если возможно)
            try:
                await query.message.reply_text(f"❌ Новость {news_id} отклонена и удалена.")
            except Exception as notify_error:
                logger.warning(f"Не удалось отправить уведомление об отклонении: {notify_error}")

            # Удаляем основное сообщение и все связанные сообщения
            if news_item.get("preview_message_ids") and news_item.get("preview_chat_id"):
                # Сначала удаляем сообщения превью из личного чата
                await safe_delete_messages(
                    context.bot,
                    news_item["preview_chat_id"],
                    news_item["preview_message_ids"],
                    news_id
                )
                logger.info(
                    f"Удалены сообщения превью из личного чата {news_item['preview_chat_id']}: {news_item['preview_message_ids']}")

            # Удаляем основное сообщение из канала модерации
            await safe_delete_messages(context.bot, channel_id, [message_id], news_id)

            # Удаляем запись из базы данных
            db.delete_news(news_id)
            logger.info(f"Новость {news_id} отклонена и удалена из модерации.")

        elif action == "edit":
            # Показываем полный текст статьи в нескольких сообщениях
            full_text = news_item.get("full_text", "")
            if full_text:
                # Отправляем заголовок
                header_message = await query.message.reply_text(
                    f"📝 Текущий полный текст новости (ID: {news_id}):"
                )

                # Отправляем текст частями и сохраняем ID всех сообщений
                text_message_ids = await split_and_send_text(context.bot, query.message.chat_id, full_text)

                # Сохраняем ID всех сообщений с превью И chat_id в базе данных
                all_preview_ids = [header_message.message_id] + text_message_ids

                # Update database - handle both old and new database types
                if hasattr(db, 'update_news'):
                    # New database
                    updates = {
                        "news_data.preview_message_ids": all_preview_ids,
                        "news_data.preview_chat_id": query.message.chat_id
                    }
                    db.update_news(news_id, updates)
                else:
                    # Old database
                    db.news_db[news_id]["news_data"]["preview_message_ids"] = all_preview_ids
                    db.news_db[news_id]["news_data"]["preview_chat_id"] = query.message.chat_id
                    db.save_db()

                logger.info(
                    f"Сохранены ID сообщений с превью для новости {news_id}: {all_preview_ids} в чате {query.message.chat_id}")
            else:
                preview_message = await query.message.reply_text("⚠️ Полный текст новости отсутствует.")
                # Сохраняем ID этого сообщения тоже
                if hasattr(db, 'update_news'):
                    updates = {
                        "news_data.preview_message_ids": [preview_message.message_id],
                        "news_data.preview_chat_id": query.message.chat_id
                    }
                    db.update_news(news_id, updates)
                else:
                    db.news_db[news_id]["news_data"]["preview_message_ids"] = [preview_message.message_id]
                    db.news_db[news_id]["news_data"]["preview_chat_id"] = query.message.chat_id
                    db.save_db()

            await query.message.reply_text(
                "✏️ Отправьте исправленный текст новости.\n"
                "Чтобы оставить как есть — отправьте /skip\n"
                "⚠️ После редактирования сообщение в канале модерации будет обновлено."
            )

            # Store editing session globally (fix for context issues)
            user_id = update.effective_user.id if update.effective_user else "unknown"
            EDITING_SESSIONS[user_id] = news_id

            # Also try to set in context if available
            if context.user_data is not None:
                context.user_data["editing_news_id"] = news_id

    except Exception as e:
        logger.error(f"Ошибка обработки callback: {e}")
        try:
            await query.edit_message_text(f"⚠️ Ошибка: {e}")
        except Exception:
            # Если не можем отредактировать, отправляем новое сообщение
            await query.message.reply_text(f"⚠️ Ошибка: {e}")


# --- Обработчик редактирования текста ---
async def edit_text_handler(update: Update, context: ContextTypes.DEFAULT_TYPE, db):
    logger.info(f"edit_text_handler вызван с текстом: {update.message.text[:100]}")

    user_id = update.effective_user.id if update.effective_user else "unknown"

    # Check global editing sessions first
    news_id = EDITING_SESSIONS.get(user_id)

    # Also check context if available
    if not news_id and context.user_data:
        news_id = context.user_data.get("editing_news_id")

    logger.info(f"user_id: {user_id}, editing_news_id: {news_id}")

    if not news_id:
        logger.info("Нет активного редактирования, пропускаем")
        return

    if update.message.text == "/skip":
        await update.message.reply_text("✅ Редактирование пропущено.")
        # Clear editing session
        EDITING_SESSIONS.pop(user_id, None)
        if context.user_data:
            context.user_data["editing_news_id"] = None
        return

    # Получаем данные новости
    data_entry = db.get_news(news_id)
    if not data_entry:
        await update.message.reply_text("⚠️ Новость не найдена в базе.")
        EDITING_SESSIONS.pop(user_id, None)
        if context.user_data:
            context.user_data["editing_news_id"] = None
        return

    # Обновляем текст новости
    if hasattr(db, 'update_news'):
        # New database
        updates = {
            "news_data.full_text": update.message.text,
            "news_data.edited": True
        }
        db.update_news(news_id, updates)
    else:
        # Old database
        db.news_db[news_id]["news_data"]["full_text"] = update.message.text
        db.news_db[news_id]["news_data"]["edited"] = True

    # Удаляем старые сообщения с превью, если они есть
    if data_entry["news_data"].get("preview_message_ids") and data_entry["news_data"].get("preview_chat_id"):
        await safe_delete_messages(
            context.bot,
            data_entry["news_data"]["preview_chat_id"],  # Используем сохраненный chat_id
            data_entry["news_data"]["preview_message_ids"],
            news_id
        )
        # Очищаем список ID сообщений с превью и chat_id
        if hasattr(db, 'update_news'):
            updates = {
                "news_data.preview_message_ids": [],
                "news_data.preview_chat_id": None
            }
            db.update_news(news_id, updates)
        else:
            db.news_db[news_id]["news_data"]["preview_message_ids"] = []
            db.news_db[news_id]["news_data"]["preview_chat_id"] = None

    db.save_db()

    # Отладочная информация
    logger.info(f"Текст новости {news_id} обновлен на: {update.message.text[:100]}")

    # Обновляем сообщение в канале модерации
    try:
        channel_id = data_entry["channel_id"]
        message_id = data_entry["message_id"]
        fresh_data_entry = db.get_news(news_id)
        news_item = fresh_data_entry["news_data"]

        # Проверяем, что message_id существует
        if message_id is None:
            logger.warning(f"Нельзя обновить сообщение для новости {news_id}: message_id is None")
            await update.message.reply_text(
                "✅ Текст новости обновлён!\n"
                "⚠️ Сообщение в канале модерации не найдено, но изменения сохранены.\n"
                "Нажмите кнопку 'Опубликовать' для публикации отредактированной версии."
            )
            EDITING_SESSIONS.pop(user_id, None)
            if context.user_data:
                context.user_data["editing_news_id"] = None
            return

        # Функция для безопасного экранирования HTML
        def safe_escape_html(text):
            if not text:
                return ""
            # Сначала удаляем все HTML-теги
            import re
            text = re.sub(r'<[^>]+>', '', str(text))
            # Затем экранируем специальные символы
            return text.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')

        # Безопасно обрабатываем текст для отображения
        clean_title = safe_escape_html(news_item.get("title", ""))
        clean_preview = safe_escape_html(news_item.get("preview", ""))
        clean_source = safe_escape_html(news_item.get("source", ""))
        clean_date = safe_escape_html(news_item.get("date", ""))
        clean_url = news_item.get('url', '')

        # Создаем новую кнопочную панель
        keyboard = [
            [
                InlineKeyboardButton("✅ Опубликовать", callback_data=f"approve|{news_id}"),
                InlineKeyboardButton("❌ Отклонить", callback_data=f"reject|{news_id}"),
                InlineKeyboardButton("✏️ Редактировать", callback_data=f"edit|{news_id}")
            ]
        ]

        # Формируем текст без HTML-парсинга для избежания ошибок
        updated_text = (
            f"📰 {clean_title} ✏️ ОТРЕДАКТИРОВАНО\n\n"
            f"{clean_preview}\n\n"
            f"Источник: {clean_source} ({clean_date})\n"
            f"{clean_url}"
        )

        await context.bot.edit_message_text(
            chat_id=channel_id,
            message_id=message_id,
            text=updated_text,
            reply_markup=InlineKeyboardMarkup(keyboard),
            disable_web_page_preview=True
            # Убираем parse_mode='HTML' чтобы избежать ошибок парсинга
        )

        await update.message.reply_text(
            "✅ Текст новости обновлён и сообщение в канале модерации обновлено!\n"
            "Теперь нажмите кнопку 'Опубликовать' для публикации отредактированной версии."
        )

    except Exception as update_error:
        logger.error(f"Ошибка обновления сообщения в канале модерации: {update_error}")
        await update.message.reply_text(
            "✅ Текст новости обновлён!\n"
            "⚠️ Не удалось обновить сообщение в канале модерации, но изменения сохранены.\n"
            "Нажмите кнопку 'Опубликовать' для публикации отредактированной версии."
        )

    # Clear editing session
    EDITING_SESSIONS.pop(user_id, None)
    if context.user_data:
        context.user_data["editing_news_id"] = None


# --- Обработчик команды /skip ---
async def skip_edit_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id if update.effective_user else "unknown"

    # Check global sessions first
    news_id = EDITING_SESSIONS.get(user_id)

    # Also check context
    if not news_id and context.user_data:
        news_id = context.user_data.get("editing_news_id")

    if news_id:
        EDITING_SESSIONS.pop(user_id, None)
        if context.user_data:
            context.user_data["editing_news_id"] = None
        await update.message.reply_text("✅ Редактирование пропущено.")
    else:
        await update.message.reply_text("ℹ️ Нет активного процесса редактирования.")
===== C:\Users\SK-GROUP\PycharmProjects\PythonProject\energy_news_project\bot\__init__.py =====
# Пакет для Telegram-бота модерации и публикации
===== C:\Users\SK-GROUP\PycharmProjects\PythonProject\energy_news_project\parser\async_rss_parser.py =====
# parser/async_rss_parser.py
import asyncio
import aiohttp
import feedparser
import logging
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Set
from dataclasses import dataclass, field
import time
from urllib.parse import urljoin, urlparse
import hashlib

from parser.utils import clean_text
from parser.nlp_filter import is_energy_related, translate_text
from parser.stats import update_stats

logger = logging.getLogger(__name__)


@dataclass
class FeedConfig:
    url: str
    name: str
    language: str = "ru"
    custom_headers: Dict[str, str] = field(default_factory=dict)
    rate_limit_delay: float = 1.0
    max_articles: int = 100
    enabled: bool = True


@dataclass
class ParsingResult:
    news_items: List[Dict] = field(default_factory=list)
    errors: List[str] = field(default_factory=list)
    stats: Dict = field(default_factory=dict)
    processing_time: float = 0.0


class AsyncRSSParser:
    """High-performance async RSS parser with connection pooling and rate limiting."""

    def __init__(self, max_workers: int = 10, timeout: int = 30, max_connections: int = 100):
        self.max_workers = max_workers
        self.timeout = timeout
        self.max_connections = max_connections
        self.session: Optional[aiohttp.ClientSession] = None
        self._rate_limiters: Dict[str, float] = {}

        # Feed configurations
        self.feeds = [
            FeedConfig("https://lenta.ru/rss/news", "Lenta.ru"),
            FeedConfig("https://www.interfax.ru/rss.asp", "Interfax"),
            FeedConfig("https://ria.ru/export/rss2/archive/index.xml", "RIA Novosti"),
            FeedConfig("https://www.vedomosti.ru/rss/news", "Vedomosti"),
            FeedConfig("https://hightech.fm/feed", "Hi-Tech Mail.ru"),
            FeedConfig("https://renen.ru/feed/", "RENEN - ВИЭ"),
            FeedConfig("https://energovector.com/feed/", "Энерговектор"),
            FeedConfig("https://cleantechnica.com/feed/", "CleanTechnica", "en"),
            FeedConfig("https://www.h2-view.com/feed/", "H2 View", "en"),
            FeedConfig("https://energynews.us/feed/", "Energy News Network", "en"),
            FeedConfig("https://www.greentechmedia.com/feed", "Greentech Media", "en"),
            FeedConfig("https://www.hydrogenfuelnews.com/feed/", "Hydrogen Fuel News", "en"),
            FeedConfig("https://www.pv-magazine.com/feed/", "PV Magazine", "en"),
            FeedConfig("https://www.renewableenergyworld.com/feed/", "Renewable Energy World", "en"),
            FeedConfig("https://www.energy-storage.news/feed/", "Energy Storage News", "en"),
            FeedConfig("https://eenergy.media/rubric/news/feed", "E-Energy"),
            FeedConfig("https://oilcapital.ru/rss", "Oilcapital"),
        ]

    async def __aenter__(self):
        """Async context manager entry."""
        await self._create_session()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """Async context manager exit."""
        await self._close_session()

    async def _create_session(self):
        """Create aiohttp session with optimized settings."""
        connector = aiohttp.TCPConnector(
            limit=self.max_connections,
            limit_per_host=20,
            ttl_dns_cache=300,
            use_dns_cache=True,
            keepalive_timeout=60,
            enable_cleanup_closed=True
        )

        timeout = aiohttp.ClientTimeout(total=self.timeout, connect=10)

        headers = {
            'User-Agent': 'Mozilla/5.0 (compatible; NewsBot/1.0)',
            'Accept': 'application/rss+xml, application/xml, text/xml, */*',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive'
        }

        self.session = aiohttp.ClientSession(
            connector=connector,
            timeout=timeout,
            headers=headers,
            raise_for_status=False
        )

        logger.info("HTTP session created with connection pooling")

    async def _close_session(self):
        """Close aiohttp session."""
        if self.session:
            await self.session.close()
            # Wait for underlying connections to close
            await asyncio.sleep(0.25)
            logger.info("HTTP session closed")

    async def _rate_limit(self, domain: str, delay: float):
        """Apply rate limiting per domain."""
        current_time = time.time()
        last_request = self._rate_limiters.get(domain, 0)

        if current_time - last_request < delay:
            sleep_time = delay - (current_time - last_request)
            await asyncio.sleep(sleep_time)

        self._rate_limiters[domain] = time.time()

    async def _fetch_content(self, url: str, headers: Optional[Dict] = None) -> Optional[bytes]:
        """Fetch content from URL with retries and error handling."""
        if not self.session:
            raise RuntimeError("Session not initialized")

        domain = urlparse(url).netloc
        await self._rate_limit(domain, 1.0)

        request_headers = headers or {}

        for attempt in range(3):
            try:
                async with self.session.get(url, headers=request_headers) as response:
                    if response.status == 200:
                        content = await response.read()
                        return content
                    elif response.status == 429:
                        # Rate limited
                        retry_after = int(response.headers.get('Retry-After', 60))
                        logger.warning(f"Rate limited for {url}, waiting {retry_after}s")
                        await asyncio.sleep(retry_after)
                    else:
                        logger.warning(f"HTTP {response.status} for {url}")

            except asyncio.TimeoutError:
                logger.warning(f"Timeout for {url} (attempt {attempt + 1})")
                await asyncio.sleep(2 ** attempt)
            except Exception as e:
                logger.error(f"Error fetching {url}: {e}")
                await asyncio.sleep(2 ** attempt)

        return None

    async def _extract_full_text(self, url: str) -> str:
        """Extract full text from article URL."""
        try:
            content = await self._fetch_content(url)
            if not content:
                return ""

            # Parse with BeautifulSoup in thread pool to avoid blocking
            from bs4 import BeautifulSoup

            def parse_html(content_bytes):
                try:
                    soup = BeautifulSoup(content_bytes, "html.parser")

                    # Remove unwanted elements
                    for tag in soup(['script', 'style', 'nav', 'header', 'footer', 'aside']):
                        tag.decompose()

                    # Try different content selectors
                    content_selectors = [
                        'article', '.content', '.post-content', '.entry-content',
                        '.article-body', '.post-body', '#content', '.main-content'
                    ]

                    text = ""
                    for selector in content_selectors:
                        elements = soup.select(selector)
                        if elements:
                            text = ' '.join([el.get_text(strip=True) for el in elements])
                            break

                    # Fallback to all paragraphs
                    if not text or len(text) < 100:
                        paragraphs = soup.find_all('p')
                        text = ' '.join(
                            [p.get_text(strip=True) for p in paragraphs if len(p.get_text(strip=True)) > 30])

                    return clean_text(text)

                except Exception as e:
                    logger.error(f"HTML parsing error for {url}: {e}")
                    return ""

            loop = asyncio.get_event_loop()
            full_text = await loop.run_in_executor(None, parse_html, content)
            return full_text

        except Exception as e:
            logger.error(f"Full text extraction error for {url}: {e}")
            return ""

    async def _parse_single_feed(self, feed_config: FeedConfig, classifier, stats) -> List[Dict]:
        """Parse a single RSS feed."""
        if not feed_config.enabled:
            return []

        results = []
        cutoff_date = datetime.now() - timedelta(days=21)

        try:
            # Fetch RSS content
            content = await self._fetch_content(
                feed_config.url,
                feed_config.custom_headers
            )

            if not content:
                update_stats(stats, feed_config.name, "fetch_failed")
                return results

            # Parse RSS in thread pool
            def parse_rss(content_bytes):
                return feedparser.parse(content_bytes)

            loop = asyncio.get_event_loop()
            feed = await loop.run_in_executor(None, parse_rss, content)

            if not hasattr(feed, 'entries') or not feed.entries:
                update_stats(stats, feed_config.name, "no_entries")
                return results

            # Limit articles per feed
            entries = feed.entries[:feed_config.max_articles]

            # Process entries concurrently with semaphore
            semaphore = asyncio.Semaphore(5)  # Limit concurrent article processing

            async def process_entry(entry):
                async with semaphore:
                    return await self._process_entry(
                        entry, feed_config, classifier, cutoff_date
                    )

            # Process all entries
            entry_results = await asyncio.gather(
                *[process_entry(entry) for entry in entries],
                return_exceptions=True
            )

            # Collect successful results
            for result in entry_results:
                if isinstance(result, dict):
                    results.append(result)
                    update_stats(stats, feed_config.name, "accepted")
                elif isinstance(result, Exception):
                    logger.error(f"Entry processing error in {feed_config.name}: {result}")
                    update_stats(stats, feed_config.name, "processing_error")
                else:
                    update_stats(stats, feed_config.name, "not_relevant")

            logger.info(f"Processed {len(results)} articles from {feed_config.name}")

        except Exception as e:
            logger.error(f"Feed processing error for {feed_config.name}: {e}")
            update_stats(stats, feed_config.name, "feed_error")

        return results

    async def _process_entry(self, entry, feed_config: FeedConfig, classifier, cutoff_date) -> Optional[Dict]:
        """Process a single feed entry."""
        try:
            # Check publication date
            pub_date = datetime.now()
            if hasattr(entry, "published_parsed") and entry.published_parsed:
                try:
                    pub_date = datetime(*entry.published_parsed[:6])
                except (ValueError, TypeError):
                    pass

            if pub_date < cutoff_date:
                return None

            # Extract basic info
            title = getattr(entry, 'title', '')
            summary = getattr(entry, 'summary', '')
            link = getattr(entry, 'link', '')

            if not title or not link:
                return None

            # Get full text
            full_text = await self._extract_full_text(link)

            # Combine text for relevance check
            combined_text = f"{title} {summary} {full_text}".strip()

            # Translate if needed
            if feed_config.language == "en" and combined_text:
                try:
                    combined_text = await asyncio.get_event_loop().run_in_executor(
                        None, translate_text, combined_text, "en", "ru", feed_config.name, link
                    )
                    title = await asyncio.get_event_loop().run_in_executor(
                        None, translate_text, title, "en", "ru", feed_config.name, link
                    )
                    if summary:
                        summary = await asyncio.get_event_loop().run_in_executor(
                            None, translate_text, summary, "en", "ru", feed_config.name, link
                        )
                except Exception as e:
                    logger.warning(f"Translation error for {link}: {e}")

            # Check relevance
            relevant, reason = is_energy_related(combined_text, classifier)
            if not relevant:
                return None

            # Create news item
            news_item = {
                "title": clean_text(title),
                "url": link,
                "date": pub_date.strftime("%Y-%m-%d %H:%M"),
                "source": feed_config.name,
                "preview": clean_text(summary or combined_text)[:300] + "...",
                "full_text": clean_text(full_text),
                "relevance_reason": reason,
                "language": feed_config.language,
                "processed_at": datetime.now().isoformat()
            }

            return news_item

        except Exception as e:
            logger.error(f"Entry processing error: {e}")
            return None

    async def parse_all_feeds(self, classifier=None, stats=None,
                              enabled_feeds: Optional[Set[str]] = None) -> ParsingResult:
        """Parse all RSS feeds concurrently."""
        start_time = time.time()

        # Filter feeds if specified
        feeds_to_process = self.feeds
        if enabled_feeds:
            feeds_to_process = [f for f in self.feeds if f.name in enabled_feeds]

        logger.info(f"Starting to parse {len(feeds_to_process)} RSS feeds")

        # Create semaphore to limit concurrent feeds
        semaphore = asyncio.Semaphore(self.max_workers)

        async def parse_with_semaphore(feed_config):
            async with semaphore:
                return await self._parse_single_feed(feed_config, classifier, stats)

        # Process all feeds concurrently
        try:
            feed_results = await asyncio.gather(
                *[parse_with_semaphore(feed) for feed in feeds_to_process],
                return_exceptions=True
            )

            all_news = []
            errors = []

            for i, result in enumerate(feed_results):
                if isinstance(result, list):
                    all_news.extend(result)
                elif isinstance(result, Exception):
                    feed_name = feeds_to_process[i].name
                    error_msg = f"Feed {feed_name} failed: {result}"
                    errors.append(error_msg)
                    logger.error(error_msg)

            # Remove duplicates based on URL
            seen_urls = set()
            unique_news = []

            for item in all_news:
                url = item.get('url', '')
                if url and url not in seen_urls:
                    seen_urls.add(url)
                    unique_news.append(item)

            processing_time = time.time() - start_time

            logger.info(
                f"Parsing completed: {len(unique_news)} unique articles "
                f"from {len(all_news)} total in {processing_time:.2f}s"
            )

            return ParsingResult(
                news_items=unique_news,
                errors=errors,
                stats=stats or {},
                processing_time=processing_time
            )

        except Exception as e:
            logger.error(f"Critical parsing error: {e}")
            return ParsingResult(
                news_items=[],
                errors=[f"Critical error: {e}"],
                processing_time=time.time() - start_time
            )

    def add_feed(self, url: str, name: str, **kwargs):
        """Add a new feed configuration."""
        feed_config = FeedConfig(url=url, name=name, **kwargs)
        self.feeds.append(feed_config)
        logger.info(f"Added feed: {name} ({url})")

    def remove_feed(self, name: str) -> bool:
        """Remove a feed by name."""
        original_count = len(self.feeds)
        self.feeds = [f for f in self.feeds if f.name != name]
        removed = len(self.feeds) < original_count
        if removed:
            logger.info(f"Removed feed: {name}")
        return removed

    def get_feed_status(self) -> List[Dict]:
        """Get status of all configured feeds."""
        return [
            {
                "name": feed.name,
                "url": feed.url,
                "language": feed.language,
                "enabled": feed.enabled,
                "rate_limit": feed.rate_limit_delay,
                "max_articles": feed.max_articles
            }
            for feed in self.feeds
        ]

    def enable_feed(self, name: str) -> bool:
        """Enable a feed by name."""
        for feed in self.feeds:
            if feed.name == name:
                feed.enabled = True
                logger.info(f"Enabled feed: {name}")
                return True
        return False

    def disable_feed(self, name: str) -> bool:
        """Disable a feed by name."""
        for feed in self.feeds:
            if feed.name == name:
                feed.enabled = False
                logger.info(f"Disabled feed: {name}")
                return True
        return False


# Convenience function for backward compatibility
async def parse_all_feeds(classifier=None, stats=None) -> List[Dict]:
    """Parse all feeds using the async parser."""
    async with AsyncRSSParser() as parser:
        result = await parser.parse_all_feeds(classifier, stats)
        return result.news_items
===== C:\Users\SK-GROUP\PycharmProjects\PythonProject\energy_news_project\parser\html_parser_custom.py =====
import requests
from bs4 import BeautifulSoup
from datetime import datetime
from parser.utils import clean_text
from parser.nlp_filter import is_energy_related
import logging
from requests.adapters import HTTPAdapter
from requests.packages.urllib3.util.retry import Retry

logger = logging.getLogger(__name__)

# Сессия с retry
def create_session():
    session = requests.Session()
    retry = Retry(
        total=5,
        backoff_factor=0.5,
        status_forcelist=[500,502,503,504],
        allowed_methods=["GET"]
    )
    adapter = HTTPAdapter(max_retries=retry)
    session.mount("http://", adapter)
    session.mount("https://", adapter)
    return session

session = create_session()
HEADERS = {"User-Agent": "Mozilla/5.0"}

def parse_site(url, article_selector, title_selector, preview_selector=None, date_selector=None, source_name="Unknown"):
    news_list = []
    try:
        r = session.get(url, headers=HEADERS, timeout=30)
        r.raise_for_status()
        soup = BeautifulSoup(r.text, "html.parser")
        articles = soup.select(article_selector)

        for a in articles:
            title_tag = a.select_one(title_selector)
            if not title_tag:
                continue
            title = clean_text(title_tag.get_text())
            link = title_tag.get("href")
            preview = clean_text(a.select_one(preview_selector).get_text()) if preview_selector and a.select_one(preview_selector) else ""
            date_tag = a.select_one(date_selector) if date_selector else None
            date_str = date_tag.get("datetime") if date_tag and date_tag.has_attr("datetime") else date_tag.get_text() if date_tag else ""
            date = date_str[:16] if date_str else datetime.now().strftime("%Y-%m-%d %H:%M")

            relevant, reason = is_energy_related(title + " " + preview)
            if relevant:
                news_list.append({
                    "title": title,
                    "url": link,
                    "date": date,
                    "source": source_name,
                    "preview": preview[:300] + "...",
                    "full_text": "",
                    "relevance_reason": reason,
                })
    except requests.RequestException as e:
        logger.error(f"Ошибка запроса {source_name}: {e}")
    except Exception as e:
        logger.error(f"Ошибка парсинга {source_name}: {e}")
    return news_list

def parse_eenergy_media():
    return parse_site(
        "https://eenergy.media/rubric/news",
        "div.t-news__item",
        "a.t-news__title",
        "div.t-news__preview",
        "time",
        "E-Energy"
    )

def parse_in_power():
    return parse_site(
        "https://www.in-power.ru/news/alternativnayaenergetika",
        "div.news-list-item",
        "a.news-title",
        "div.news-text",
        "div.news-date",
        "In-Power"
    )

def parse_neftegaz():
    return parse_site(
        "https://neftegaz.ru/news/Alternative-energy/",
        "div.article-preview",
        "a.article-title",
        "div.article-text",
        "div.article-date",
        "Neftegaz"
    )

def parse_oilcapital():
    return parse_site(
        "https://oilcapital.ru/tags/vie",
        "div.news-item",
        "a.title",
        "div.preview",
        "span.date",
        "Oilcapital"
    )

def parse_all_custom_sites():
    all_news = []
    all_news.extend(parse_eenergy_media())
    all_news.extend(parse_in_power())
    all_news.extend(parse_neftegaz())
    all_news.extend(parse_oilcapital())
    return all_news
===== C:\Users\SK-GROUP\PycharmProjects\PythonProject\energy_news_project\parser\logger_monitor.py =====
import logging
import time
from functools import wraps
from tqdm import tqdm
import parser.rss_parser as rss
import parser.nlp_filter as nlp
import os

LOG_DIR = os.path.join(os.path.dirname(__file__), "..", "data")
LOG_FILE = os.path.join(LOG_DIR, "parser_monitor.log")

def setup_logger():
    os.makedirs(LOG_DIR, exist_ok=True)
    logger = logging.getLogger("parser_monitor")
    logger.setLevel(logging.DEBUG)

    fh = logging.FileHandler(LOG_FILE, encoding="utf-8")
    fh.setLevel(logging.DEBUG)
    ch = logging.StreamHandler()
    ch.setLevel(logging.INFO)

    formatter = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")
    fh.setFormatter(formatter)
    ch.setFormatter(formatter)

    logger.addHandler(fh)
    logger.addHandler(ch)
    return logger

logger = setup_logger()

def log_time(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        start = time.time()
        logger.info(f"START: {func.__name__}")
        result = func(*args, **kwargs)
        logger.info(f"END: {func.__name__} | duration: {time.time()-start:.2f} sec")
        return result
    return wrapper

def monitored_get_full_text(func):
    @wraps(func)
    def wrapper(url, *args, **kwargs):
        logger.info(f"Fetching full text: {url}")
        start = time.time()
        text = func(url, *args, **kwargs)
        logger.info(f"Fetched {len(text)} chars | duration: {time.time()-start:.2f} sec")
        return text
    return wrapper

def monitored_is_energy_related(func):
    @wraps(func)
    def wrapper(text, classifier=None, *args, **kwargs):
        start = time.time()
        relevant, reason = func(text, classifier, *args, **kwargs)
        logger.info(f"Classification: relevant={relevant} | reason={reason} | duration={time.time()-start:.2f} sec")
        return relevant, reason
    return wrapper

def monitored_parse_all_feeds(func):
    @wraps(func)
    def wrapper(classifier=None, stats=None, *args, **kwargs):
        rss.RSS_FEEDS = list(tqdm(rss.RSS_FEEDS, desc="RSS Feeds"))
        logger.info("Starting parse_all_feeds")
        all_news = func(classifier=classifier, stats=stats, *args, **kwargs)
        logger.info(f"Finished parse_all_feeds | total news: {len(all_news)}")
        return all_news
    return wrapper

rss.get_full_text = monitored_get_full_text(rss.get_full_text)
nlp.is_energy_related = monitored_is_energy_related(nlp.is_energy_related)
rss.parse_all_feeds = monitored_parse_all_feeds(rss.parse_all_feeds)
===== C:\Users\SK-GROUP\PycharmProjects\PythonProject\energy_news_project\parser\nlp_filter.py =====
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline
from deep_translator import GoogleTranslator
import logging

logger = logging.getLogger(__name__)

EXPANDED_KEYWORDS = [
    "энергетик", "виэ", "водород", "акб", "экологи", "декарбонизац", "возобнов", "электромобил",
    "экотех", "климат", "энергопереход", "renewable", "solar", "wind", "battery", "hydrogen",
    "decarbonization", "sustainability", "green energy", "clean tech", "photovoltaic", "wind turbine",
    "энергоэффективность", "биотопливо", "геотермальный", "приливная энергия", "энергосбережение"
]

def load_classification_model():
    logger.info("Загрузка модели классификации...")
    try:
        model_name = "cointegrated/rubert-tiny2-cedr-emotion-detection"
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForSequenceClassification.from_pretrained(model_name)
        classifier = pipeline(
            "text-classification",
            model=model,
            tokenizer=tokenizer,
            device=0 if torch.cuda.is_available() else -1
        )
        logger.info("Модель загружена")
        return classifier
    except Exception as e:
        logger.error(f"Ошибка загрузки модели: {str(e)}")
        return None

def is_energy_related(text, classifier=None, threshold=0.90):
    if not text.strip():
        return False, "Пустой текст"
    text_lower = text.lower()
    keyword_count = sum(1 for keyword in EXPANDED_KEYWORDS if keyword.lower() in text_lower)
    if keyword_count >= 2:
        return True, f"Найдено {keyword_count} ключевых слов"
    if not classifier:
        return keyword_count > 0, "Проверка только по ключевым словам"
    try:
        result = classifier(text[:400], truncation=True, max_length=512)
        for res in result:
            if res['label'] == 'neutral' and res['score'] > threshold:
                return True, f"ИИ-классификация ({res['score']:.2f})"
        return False, "Нерелевантно"
    except Exception as e:
        logger.error(f"Ошибка классификации: {str(e)}")
        return keyword_count > 0, "Ошибка ИИ"

def translate_text(text, src="en", dest="ru", source_name=None, article_url=None):
    if not text.strip():
        return text
    try:
        max_chunk_size = 4500
        chunks = [text[i:i + max_chunk_size] for i in range(0, len(text), max_chunk_size)]
        translated = [GoogleTranslator(source=src, target=dest).translate(chunk) for chunk in chunks]
        return " ".join(translated)
    except Exception as e:
        logger.warning(f"Ошибка перевода ({source_name or '???'} - {article_url or ''}): {str(e)}")
        return text
===== C:\Users\SK-GROUP\PycharmProjects\PythonProject\energy_news_project\parser\rss_parser.py =====
import feedparser
import requests
from datetime import datetime, timedelta
from bs4 import BeautifulSoup
from parser.utils import clean_text
from parser.nlp_filter import is_energy_related
from parser.stats import update_stats
import logging
from requests.adapters import HTTPAdapter
from requests.packages.urllib3.util.retry import Retry

logger = logging.getLogger(__name__)

RSS_FEEDS = [
    {"url": "https://lenta.ru/rss/news", "name": "Lenta.ru"},
    {"url": "https://www.interfax.ru/rss.asp", "name": "Interfax"},
    {"url": "https://ria.ru/export/rss2/archive/index.xml", "name": "RIA Novosti"},
    {"url": "https://www.vedomosti.ru/rss/news", "name": "Vedomosti"},
    {"url": "https://hightech.fm/feed", "name": "Hi-Tech Mail.ru"},
    # {"url": "https://recyclemag.ru/rss.xml", "name": "Recyclemag"}, # don't work
    # {"url": "https://www.kommersant.ru/RSS/news/energy", "name": "Коммерсантъ Энергетика"}, # don't work
    # {"url": "https://tass.ru/rss/economy.xml", "name": "ТАСС Экономика"}, # don't work
    # {"url": "https://ria.ru/export/rss2/tech/index.xml", "name": "РИА Наука"}, # don't work
    # {"url": "http://energosovet.ru/rss.xml", "name": "Энергосовет"}, # don't work
    {"url": "https://renen.ru/feed/", "name": "RENEN - ВИЭ"},
    # {"url": "https://greenevolution.ru/feed/", "name": "Green Evolution"}, # don't work
    {"url": "https://energovector.com/feed/", "name": "Энерговектор"},
    # {"url": "https://www.reutersagency.com/feed/?best-topics=energy&post_type=best", "name": "Reuters Energy"}, # don't work
    # {"url": "https://www.bloomberg.com/feeds/bbiz/sustainability.xml", "name": "Bloomberg Green"}, # don't work
    {"url": "https://cleantechnica.com/feed/", "name": "CleanTechnica"},
    {"url": "https://www.h2-view.com/feed/", "name": "H2 View"},
    {"url": "https://energynews.us/feed/", "name": "Energy News Network"},
    {"url": "https://www.greentechmedia.com/feed", "name": "Greentech Media"},
    {"url": "https://www.hydrogenfuelnews.com/feed/", "name": "Hydrogen Fuel News"},
    {"url": "https://www.pv-magazine.com/feed/", "name": "PV Magazine"},
    {"url": "https://www.renewableenergyworld.com/feed/", "name": "Renewable Energy World"},
    # {"url": "https://www.greencarcongress.com/index.xml", "name": "Green Car Congress"}, # не работает
    {"url": "https://www.energy-storage.news/feed/", "name": "Energy Storage News"},
    {"url": "https://eenergy.media/rubric/news/feed", "name": "E-Energy"}, # работает
    # {"url": "https://www.in-power.ru/news/alternativnayaenergetika", "name": "In-Power"}, # не работает
    # {"url": "https://neftegaz.ru/news/Alternative-energy", "name": "Neftegaz"}, # не работает
    {"url": "https://oilcapital.ru/rss", "name": "Oilcapital"}, # работает
    {"url": "https://renen.ru/feed", "name": "renen"}, # работает
]

# Сессия с retry
session = requests.Session()
retry = Retry(total=5, backoff_factor=0.5, status_forcelist=[500,502,503,504], allowed_methods=["GET"])
adapter = HTTPAdapter(max_retries=retry)
session.mount("http://", adapter)
session.mount("https://", adapter)
HEADERS = {"User-Agent": "Mozilla/5.0"}

def get_full_text(url):
    base_url = url.split('?')[0]
    try:
        response = session.get(base_url, headers=HEADERS, timeout=30)
        response.raise_for_status()
        response.encoding = response.apparent_encoding
        soup = BeautifulSoup(response.text, "html.parser")
        text = " ".join([p.get_text(strip=True) for p in soup.select("p") if len(p.get_text(strip=True)) > 30])
        return clean_text(text)
    except requests.ConnectionError as e:
        logger.warning(f"Connection error {url}: {e}")
        return ""
    except requests.RequestException as e:
        logger.warning(f"Request error {url}: {e}")
        return ""
    except Exception as e:
        logger.warning(f"Unexpected error {url}: {e}")
        return ""

def parse_feed(feed_url, source_name, classifier, stats):
    results = []
    three_weeks_ago = datetime.now() - timedelta(days=21)
    try:
        response = session.get(feed_url, headers=HEADERS, timeout=30)
        response.raise_for_status()
        feed = feedparser.parse(response.content)
    except Exception as e:
        logger.error(f"Ошибка запроса RSS {feed_url}: {e}")
        update_stats(stats, source_name, "failed_request")
        return results

    for entry in feed.entries:
        pub_date = datetime.now()
        if hasattr(entry, "published_parsed"):
            pub_date = datetime(*entry.published_parsed[:6])
        if pub_date < three_weeks_ago:
            update_stats(stats, source_name, "old_date")
            continue

        content = entry.title + " " + getattr(entry, "summary", "")
        full_text = get_full_text(entry.link)
        combined_text = content + " " + full_text

        relevant, reason = is_energy_related(combined_text, classifier)
        if relevant:
            news = {
                "title": entry.title,
                "url": entry.link,
                "date": pub_date.strftime("%Y-%m-%d %H:%M"),
                "source": source_name,
                "preview": combined_text[:300] + "...",
                "full_text": full_text,
                "relevance_reason": reason,
            }
            results.append(news)
            update_stats(stats, source_name, "accepted")
        else:
            update_stats(stats, source_name, "not_relevant")
    return results

def parse_all_feeds(classifier=None, stats=None):
    all_news = []
    for feed in RSS_FEEDS:
        news = parse_feed(feed["url"], feed["name"], classifier, stats)
        all_news.extend(news)
    return all_news
===== C:\Users\SK-GROUP\PycharmProjects\PythonProject\energy_news_project\parser\stats.py =====
import json
from collections import defaultdict
from datetime import datetime
import os

def init_stats():
    return {
        "total_articles": 0,
        "accepted": 0,
        "rejected": defaultdict(int),
        "failed_sources": [],
        "source_details": {},
        "start_time": datetime.now()
    }

def update_stats(stats, source, reason):
    source_stats = stats["source_details"].setdefault(
        source, {"total": 0, "accepted": 0, "rejected": defaultdict(int), "errors": []}
    )
    stats["total_articles"] += 1
    source_stats["total"] += 1

    if reason == "accepted":
        stats["accepted"] += 1
        source_stats["accepted"] += 1
    else:
        stats["rejected"][reason] += 1
        source_stats["rejected"][reason] += 1

def generate_stats_report(stats):
    report = "\n===== СТАТИСТИКА ОБРАБОТКИ =====\n"
    report += f"Всего статей: {stats['total_articles']}\n"
    report += f"Принято: {stats['accepted']}\n"
    report += f"Отклонено: {stats['total_articles'] - stats['accepted']}\n"
    return report

def save_results(all_news, stats, timestamp):
    # Создаём папку data, если её нет
    os.makedirs("data", exist_ok=True)

    json_filename = f"data/energy_news_{timestamp}.json"
    stats_filename = f"data/processing_stats_{timestamp}.txt"

    with open(json_filename, "w", encoding="utf-8") as f:
        json.dump(all_news, f, indent=2, ensure_ascii=False)

    with open(stats_filename, "w", encoding="utf-8") as f:
        f.write(generate_stats_report(stats))

    return json_filename, stats_filename
===== C:\Users\SK-GROUP\PycharmProjects\PythonProject\energy_news_project\parser\utils.py =====
import re
import html

def clean_text(text: str) -> str:
    if not text:
        return ""
    text = re.sub(r"<[^>]+>", " ", text)
    text = re.sub(r"https?://\S+", " ", text)
    text = re.sub(r"\s+", " ", text).strip()
    return html.unescape(text)
===== C:\Users\SK-GROUP\PycharmProjects\PythonProject\energy_news_project\parser\__init__.py =====
# Пакет для парсинга и анализа новостей
===== C:\Users\SK-GROUP\PycharmProjects\PythonProject\energy_news_project\config.py =====
# config.py
import os
from dataclasses import dataclass
from typing import List, Dict
import json

try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass  # python-dotenv not installed

@dataclass
class TelegramConfig:
    bot_token: str
    moderation_channel: str
    publish_channel: str
    max_message_length: int = 4000
    retry_attempts: int = 5
    flood_control_delay: float = 1.5


@dataclass
class ParserConfig:
    max_workers: int = 10
    request_timeout: int = 30
    retry_attempts: int = 5
    days_back: int = 21
    batch_size: int = 50


@dataclass
class DatabaseConfig:
    db_file: str = "data/news_db.json"
    sent_ids_file: str = "data/sent_ids.json"
    backup_interval: int = 3600  # seconds


@dataclass
class Config:
    telegram: TelegramConfig
    parser: ParserConfig
    database: DatabaseConfig
    debug: bool = False
    log_level: str = "INFO"


def load_config() -> Config:
    """Load configuration from environment variables and config file."""

    # Try to load from config file first
    config_file = os.getenv("CONFIG_FILE", "config.json")
    config_data = {}

    if os.path.exists(config_file):
        with open(config_file, "r", encoding="utf-8") as f:
            config_data = json.load(f)

    # Override with environment variables
    telegram_config = TelegramConfig(
        bot_token=os.getenv("TELEGRAM_BOT_TOKEN", config_data.get("telegram", {}).get("bot_token", "")),
        moderation_channel=os.getenv("MODERATION_CHANNEL",
                                     config_data.get("telegram", {}).get("moderation_channel", "-1002996332660")),
        publish_channel=os.getenv("PUBLISH_CHANNEL",
                                  config_data.get("telegram", {}).get("publish_channel", "-1003006895565")),
        max_message_length=int(
            os.getenv("MAX_MESSAGE_LENGTH", config_data.get("telegram", {}).get("max_message_length", 4000))),
        retry_attempts=int(
            os.getenv("TELEGRAM_RETRY_ATTEMPTS", config_data.get("telegram", {}).get("retry_attempts", 5))),
        flood_control_delay=float(
            os.getenv("FLOOD_CONTROL_DELAY", config_data.get("telegram", {}).get("flood_control_delay", 1.5)))
    )

    parser_config = ParserConfig(
        max_workers=int(os.getenv("PARSER_MAX_WORKERS", config_data.get("parser", {}).get("max_workers", 10))),
        request_timeout=int(os.getenv("REQUEST_TIMEOUT", config_data.get("parser", {}).get("request_timeout", 30))),
        retry_attempts=int(os.getenv("PARSER_RETRY_ATTEMPTS", config_data.get("parser", {}).get("retry_attempts", 5))),
        days_back=int(os.getenv("DAYS_BACK", config_data.get("parser", {}).get("days_back", 21))),
        batch_size=int(os.getenv("BATCH_SIZE", config_data.get("parser", {}).get("batch_size", 50)))
    )

    database_config = DatabaseConfig(
        db_file=os.getenv("DB_FILE", config_data.get("database", {}).get("db_file", "data/news_db.json")),
        sent_ids_file=os.getenv("SENT_IDS_FILE",
                                config_data.get("database", {}).get("sent_ids_file", "data/sent_ids.json")),
        backup_interval=int(os.getenv("BACKUP_INTERVAL", config_data.get("database", {}).get("backup_interval", 3600)))
    )

    return Config(
        telegram=telegram_config,
        parser=parser_config,
        database=database_config,
        debug=os.getenv("DEBUG", "false").lower() == "true",
        log_level=os.getenv("LOG_LEVEL", config_data.get("log_level", "INFO"))
    )


def create_sample_config():
    """Create a sample configuration file."""
    sample_config = {
        "telegram": {
            "bot_token": "8217915867:AAFLPnQmnxhHmjloF4Ct3HhR9jjRjVYV6C8",
            "moderation_channel": "-1002996332660",
            "publish_channel": "-1003006895565",
            "max_message_length": 4000,
            "retry_attempts": 5,
            "flood_control_delay": 1.5
        },
        "parser": {
            "max_workers": 10,
            "request_timeout": 30,
            "retry_attempts": 5,
            "days_back": 21,
            "batch_size": 50
        },
        "database": {
            "db_file": "data/news_db.json",
            "sent_ids_file": "data/sent_ids.json",
            "backup_interval": 3600
        },
        "debug": False,
        "log_level": "INFO"
    }

    with open("config.json.example", "w", encoding="utf-8") as f:
        json.dump(sample_config, f, indent=2, ensure_ascii=False)


if __name__ == "__main__":
    create_sample_config()
    print("Sample configuration file created: config.json.example")
===== C:\Users\SK-GROUP\PycharmProjects\PythonProject\energy_news_project\main_bot.py =====
# main_bot.py
import sys
import os

# Add current directory to path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from bot.bot_runner_simple import run_bot

if __name__ == "__main__":
    run_bot()
===== C:\Users\SK-GROUP\PycharmProjects\PythonProject\energy_news_project\main_parser.py =====
# main_parser.py
from parser.rss_parser import parse_all_feeds
from parser.html_parser_custom import parse_all_custom_sites
from parser.stats import init_stats, generate_stats_report, save_results
from parser.nlp_filter import load_classification_model
from parser.logger_monitor import logger
from datetime import datetime

if __name__ == "__main__":
    logger.info("Запуск парсера новостей")

    # --- Инициализация статистики и модели ---
    stats = init_stats()
    classifier = load_classification_model()

    # --- 1) Парсим RSS-фиды ---
    logger.info("Парсинг RSS-фидов")
    rss_news = parse_all_feeds(classifier=classifier, stats=stats)
    logger.info(f"Найдено {len(rss_news)} новостей из RSS")

    # --- 2) Парсим кастомные HTML-сайты ---
    logger.info("Парсинг HTML-сайтов")
    html_news = parse_all_custom_sites()
    logger.info(f"Найдено {len(html_news)} новостей с HTML-сайтов")

    # --- 3) Объединяем все новости ---
    all_news = rss_news + html_news
    logger.info(f"Всего новостей: {len(all_news)}")

    # --- 4) Сохраняем результаты ---
    if all_news:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M")
        json_file, stats_file = save_results(all_news, stats, timestamp)
        logger.info(f"Сохранено {len(all_news)} новостей в {json_file}")
        logger.info(generate_stats_report(stats))
    else:
        logger.info("Новости не найдены")
